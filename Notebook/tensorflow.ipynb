{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "weather_df = pd.read_csv('weather_data.csv')\n",
    "observations_df = pd.read_csv('observations.csv')\n",
    "\n",
    "# convert datetime to same format as observations_df\n",
    "weather_df['Datetime'] = pd.to_datetime(weather_df['Datetime'], format='%Y%m%d%H')\n",
    "weather_df['Date'] = weather_df['Datetime'].dt.date\n",
    "\n",
    "# Use same format as weather_df\n",
    "observations_df['Date'] = pd.to_datetime(observations_df[['year', 'month', 'day']])\n",
    "\n",
    "# Group by id and Date to find all unique days per ID\n",
    "day_indices = weather_df.groupby(['id', 'Date']).first().reset_index()\n",
    "\n",
    "# remove windspeed and specific humidity columns\n",
    "day_indices = day_indices.drop(columns=['Wind Speed', 'Specific Humidity'])\n",
    "\n",
    "# make dict of observation ID with original date\n",
    "observation_dates = {}\n",
    "for _, row in observations_df.iterrows():\n",
    "    observation_dates[row['id']] = row['Date']\n",
    "\n",
    "# Calculate difference between observation date and weather date\n",
    "def get_relative_day(row):\n",
    "    obs_date = observation_dates.get(row['id'])\n",
    "    this_date = pd.to_datetime(row['Date'])\n",
    "    difference = (this_date - obs_date).days\n",
    "    return difference\n",
    "\n",
    "# Apply the function to get relative day\n",
    "day_indices['RelativeDay'] = day_indices.apply(get_relative_day, axis=1)\n",
    "\n",
    "# Add relative day to weather_df\n",
    "day_map = day_indices.set_index(['id', 'Date'])['RelativeDay']\n",
    "weather_df['RelativeDay'] = weather_df.set_index(['id', 'Date']).index.map(day_map)\n",
    "\n",
    "# Variables to calculate aggregations for\n",
    "weather_vars = ['Temperature', 'Humidity','Dew/Frost Point', \n",
    "                'Wet Bulb Temperature', 'Precipitation', 'Soil Temperature']\n",
    "\n",
    "# Time windows to aggregate over (days before and after the observation day)\n",
    "time_windows = {\n",
    "    'day_of': (0, 0),\n",
    "    'day_before_after': (-1, 1),\n",
    "    'three_days': (-3, 3),\n",
    "    'one_week': (-7, 7),\n",
    "    'two_weeks': (-14, 14)\n",
    "}\n",
    "\n",
    "# Function to calculate aggregates given ID and time window\n",
    "def calculate_aggregates(weather_subset, var_name, window_name, start_day, end_day):\n",
    "    # Filter data for given time window\n",
    "    window_data = weather_subset[(weather_subset['RelativeDay'] >= start_day) & (weather_subset['RelativeDay'] <= end_day)]\n",
    "    \n",
    "    # Calculate aggregate and return as a series\n",
    "    result = pd.Series({\n",
    "        f\"{var_name}_{window_name}_mean\": window_data[var_name].mean(),\n",
    "        f\"{var_name}_{window_name}_min\": window_data[var_name].min(),\n",
    "        f\"{var_name}_{window_name}_max\": window_data[var_name].max(),\n",
    "        f\"{var_name}_{window_name}_median\": window_data[var_name].median()\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Create empty DataFrame to store results\n",
    "all_features = []\n",
    "result_rows = []\n",
    "\n",
    "# For each observation row, calculate all aggregate weather data\n",
    "for id_val in observations_df['id'].unique():\n",
    "    id_weather = weather_df[weather_df['id'] == id_val]\n",
    "        \n",
    "    # Dictionary to store aggregated values for this ID\n",
    "    id_features = {'id': id_val}\n",
    "    \n",
    "    # Iterate over all weather data variables\n",
    "    for var in weather_vars:\n",
    "        # iterate over all items in time_windows\n",
    "        for window_name, (start_day, end_day) in time_windows.items():\n",
    "            aggs = calculate_aggregates(id_weather, var, window_name, start_day, end_day)\n",
    "            id_features.update(aggs)\n",
    "            \n",
    "            # Add feature names to our list (only once)\n",
    "            if id_val == observations_df['id'].unique()[0]:\n",
    "                all_features.extend(aggs.index.tolist())\n",
    "    \n",
    "    result_rows.append(id_features)\n",
    "\n",
    "# Create DataFrame from results\n",
    "aggregated_features = pd.DataFrame(result_rows)\n",
    "\n",
    "# Merge with the original observations dataframe\n",
    "observations_df = observations_df.merge(aggregated_features, on='id', how='left')\n",
    "\n",
    "# Create list of feature names\n",
    "weather_feature_names = all_features\n",
    "\n",
    "print(f\"Created {len(weather_feature_names)}  features\")\n",
    "\n",
    "\n",
    "\n",
    "# Add day of year as a feature to observations_df\n",
    "observations_df['day_of_year'] = observations_df.apply(\n",
    "    lambda row: datetime(row['year'], row['month'], row['day']).timetuple().tm_yday, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop rows with NaN values\n",
    "observations_df = observations_df.dropna()\n",
    "\n",
    "# Display the updated DataFrame\n",
    "observations_df.head()\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "observations_df.to_csv('observations_with_weather_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# Define the features and target variable\n",
    "features = weather_feature_names + ['day_of_year']\n",
    "target = 'PowderyMildew'\n",
    "\n",
    "X = observations_df[features]\n",
    "y = observations_df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(len(features),)),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1, activation ='sigmoid')  # Output layer\n",
    "])\n",
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Save the model\n",
    "model.save('powdery_mildew_model.h5')\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('powdery_mildew_model.h5')\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(X_test)\n",
    "# Display predictions\n",
    "predictions_df = pd.DataFrame({'Predicted': predictions.flatten(), 'Actual': y_test})\n",
    "predictions_df.head()\n",
    "\n",
    "# test and output confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "# Convert predictions to binary classification\n",
    "threshold = 0.5\n",
    "y_pred_binary = (predictions.flatten() > threshold).astype(int)\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_binary)\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_binary, target_names=['No', 'Yes']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a decision tree classifier\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "observations_df = pd.read_csv('observations_with_weather_features.csv')\n",
    "# split df into train and test\n",
    "train=observations_df.sample(frac=0.8,random_state=200)\n",
    "test=observations_df.drop(train.index)\n",
    "\n",
    "train.drop(columns=['Date', 'coordinates', 'date_string'], inplace=True)\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=\"PowderyMildew\")\n",
    "\n",
    "test.drop(columns=['Date', 'coordinates', 'date_string'], inplace=True)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test, label=\"PowderyMildew\")\n",
    "\n",
    "tuner = tfdf.tuner.RandomSearch(num_trials=50)\n",
    "\n",
    "tuner.choice(\"min_examples\", [2, 5, 7, 10])\n",
    "tuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n",
    "\n",
    "local_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\n",
    "local_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8])\n",
    "\n",
    "# merge=True indicates that the parameter (here \"growing_strategy\") is already\n",
    "# defined, and that new values are added to it.\n",
    "global_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\n",
    "global_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n",
    "\n",
    "tuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = tfdf.keras.RandomForestModel(verbose=2,tuner=tuner)\n",
    "# Train the model\n",
    "model.compile(metrics=[\"accuracy\"])\n",
    "model.fit(train_ds)\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(test_ds)\n",
    "print(evaluation)\n",
    "# Make predictions\n",
    "predictions = model.predict(test_ds)\n",
    "# Convert predictions to binary classification\n",
    "threshold = 0.5\n",
    "y_pred_binary = (predictions.flatten() > threshold).astype(int)\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(test['PowderyMildew'], y_pred_binary)\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "# Print classification report\n",
    "print(classification_report(test['PowderyMildew'], y_pred_binary, target_names=['No', 'Yes']))\n",
    "\n",
    "# save model\n",
    "model.save(\"powdery_mildew_model_decision_tree\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a decision tree classifier\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "observations_df = pd.read_csv('observations_with_weather_features.csv')\n",
    "# split df into train and test\n",
    "train=observations_df.sample(frac=0.8,random_state=200)\n",
    "test=observations_df.drop(train.index)\n",
    "\n",
    "train.drop(columns=['Date', 'coordinates', 'date_string'], inplace=True)\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train, label=\"PowderyMildew\")\n",
    "\n",
    "test.drop(columns=['Date', 'coordinates', 'date_string'], inplace=True)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test, label=\"PowderyMildew\")\n",
    "\n",
    "# Create a Random Search tuner with 50 trials and automatic hp configuration.\n",
    "tuner = tfdf.tuner.RandomSearch(num_trials=50, use_predefined_hps=True)\n",
    "\n",
    "# Define and train the model.\n",
    "model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\n",
    "model.fit(train_ds, verbose=2)\n",
    "\n",
    "# Train the model\n",
    "model.compile(metrics=[\"accuracy\"])\n",
    "model.fit(train_ds)\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(test_ds)\n",
    "print(evaluation)\n",
    "# Make predictions\n",
    "predictions = model.predict(test_ds)\n",
    "# Convert predictions to binary classification\n",
    "threshold = 0.5\n",
    "y_pred_binary = (predictions.flatten() > threshold).astype(int)\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(test['PowderyMildew'], y_pred_binary)\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "# Print classification report\n",
    "print(classification_report(test['PowderyMildew'], y_pred_binary, target_names=['No', 'Yes']))\n",
    "\n",
    "# Save the model\n",
    "model.save('gradient_boosted_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
