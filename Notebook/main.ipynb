{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 15,
>>>>>>> 4e687d2c634c322085eee218f4bf4ed521d78180
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": 16,
>>>>>>> 4e687d2c634c322085eee218f4bf4ed521d78180
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Init Variables\n",
    "GET_WEATHER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_string</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>PowderyMildew</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48688154</td>\n",
       "      <td>2020-06-06T14:17:01-04:00</td>\n",
       "      <td>[-73.9520673641, 40.7700205967]</td>\n",
       "      <td>True</td>\n",
       "      <td>-73.952067</td>\n",
       "      <td>40.770021</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116476822</td>\n",
       "      <td>2022-05-10T16:37:09-04:00</td>\n",
       "      <td>[-73.95191313710001, 40.7701800205]</td>\n",
       "      <td>True</td>\n",
       "      <td>-73.951913</td>\n",
       "      <td>40.770180</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169576529</td>\n",
       "      <td>2023-06-26T09:10:01+02:00</td>\n",
       "      <td>[8.80802725, 50.8119201389]</td>\n",
       "      <td>True</td>\n",
       "      <td>8.808027</td>\n",
       "      <td>50.811920</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206356226</td>\n",
       "      <td>2024-04-09T19:08:00-04:00</td>\n",
       "      <td>[-76.3073433611, 38.9860498889]</td>\n",
       "      <td>True</td>\n",
       "      <td>-76.307343</td>\n",
       "      <td>38.986050</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162498461</td>\n",
       "      <td>2023-05-19T16:44:24+02:00</td>\n",
       "      <td>[12.9216153547, 48.6943073404]</td>\n",
       "      <td>True</td>\n",
       "      <td>12.921615</td>\n",
       "      <td>48.694307</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                date_string  ... month  day\n",
       "0   48688154  2020-06-06T14:17:01-04:00  ...     6    6\n",
       "1  116476822  2022-05-10T16:37:09-04:00  ...     5   10\n",
       "2  169576529  2023-06-26T09:10:01+02:00  ...     6   26\n",
       "3  206356226  2024-04-09T19:08:00-04:00  ...     4    9\n",
       "4  162498461  2023-05-19T16:44:24+02:00  ...     5   19\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read observations file that already has the PowderyMildew feature\n",
    "observations_df = pd.read_csv('observations.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "observations_df = observations_df.dropna()\n",
    "\n",
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_string</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>PowderyMildew</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48688154</td>\n",
       "      <td>2020-06-06T14:17:01-04:00</td>\n",
       "      <td>[-73.9520673641, 40.7700205967]</td>\n",
       "      <td>True</td>\n",
       "      <td>-73.952067</td>\n",
       "      <td>40.770021</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116476822</td>\n",
       "      <td>2022-05-10T16:37:09-04:00</td>\n",
       "      <td>[-73.95191313710001, 40.7701800205]</td>\n",
       "      <td>True</td>\n",
       "      <td>-73.951913</td>\n",
       "      <td>40.770180</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169576529</td>\n",
       "      <td>2023-06-26T09:10:01+02:00</td>\n",
       "      <td>[8.80802725, 50.8119201389]</td>\n",
       "      <td>True</td>\n",
       "      <td>8.808027</td>\n",
       "      <td>50.811920</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206356226</td>\n",
       "      <td>2024-04-09T19:08:00-04:00</td>\n",
       "      <td>[-76.3073433611, 38.9860498889]</td>\n",
       "      <td>True</td>\n",
       "      <td>-76.307343</td>\n",
       "      <td>38.986050</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162498461</td>\n",
       "      <td>2023-05-19T16:44:24+02:00</td>\n",
       "      <td>[12.9216153547, 48.6943073404]</td>\n",
       "      <td>True</td>\n",
       "      <td>12.921615</td>\n",
       "      <td>48.694307</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                date_string  ... month  day\n",
       "0   48688154  2020-06-06T14:17:01-04:00  ...     6    6\n",
       "1  116476822  2022-05-10T16:37:09-04:00  ...     5   10\n",
       "2  169576529  2023-06-26T09:10:01+02:00  ...     6   26\n",
       "3  206356226  2024-04-09T19:08:00-04:00  ...     4    9\n",
       "4  162498461  2023-05-19T16:44:24+02:00  ...     5   19\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to parse date string and extract components\n",
    "def extract_date_components(date_string):\n",
    "    import datetime\n",
    "    # Parse ISO format date string\n",
    "    dt = datetime.datetime.fromisoformat(date_string.replace('Z', '+00:00'))\n",
    "    return dt.year, dt.month, dt.day\n",
    "\n",
    "# Extract relevant data for true observations\n",
    "lons = []\n",
    "lats = []\n",
    "years = []\n",
    "months = []\n",
    "days = []\n",
    "\n",
    "for _, row in observations_df.iterrows():\n",
    "    # Parse the coordinates string into a list of floats\n",
    "    coords = eval(row['coordinates'])\n",
    "    lons.append(coords[0])\n",
    "    lats.append(coords[1])\n",
    "    \n",
    "    # Extract the date components from the date_string\n",
    "    year, month, day = extract_date_components(row['date_string'])\n",
    "    years.append(year)\n",
    "    months.append(month)\n",
    "    days.append(day)\n",
    "    \n",
    "# Apply parsed data to the observations_df\n",
    "observations_df['longitude'] = lons\n",
    "observations_df['latitude'] = lats\n",
    "observations_df['year'] = years\n",
    "observations_df['month'] = months\n",
    "observations_df['day'] = days\n",
    "\n",
    "observations_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": 19,
>>>>>>> 4e687d2c634c322085eee218f4bf4ed521d78180
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NASA weather data at given coordinates 7 days before and after the given date\n",
    "# \n",
    "# Parameters:\n",
    "#   lon (float): Longitude coordinate\n",
    "#   lat (float): Latitude coordinate\n",
    "#   day (int): Day of the month\n",
    "#   month (int): Month of the year\n",
    "#   year (int): Year\n",
    "#   param_list (list): List of weather parameters to retrieve\n",
    "#\n",
    "# Returns:\n",
    "#   dict: Dictionary containing the requested weather parameters with their values,\n",
    "#\n",
    "\n",
    "def get_general_weather(lon, lat, day, month, year, param_list):\n",
    "    url = \"https://power.larc.nasa.gov/api/temporal/hourly/point\"\n",
    "    \n",
    "    month_str = str(month).zfill(2)  # make sure is 2 length\n",
    "    day_str = str(day).zfill(2)      # same as above\n",
    "    start_date = f\"{year}-{month_str}-{day_str}\"\n",
    "\n",
    "    start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\") \n",
    "    end_date = start_date\n",
    "    start_date -= datetime.timedelta(days=21)\n",
    "\n",
    "    start_date = start_date.strftime(\"%Y%m%d\")\n",
    "    end_date = end_date.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    parameters = {\n",
    "        \"parameters\": \",\".join(param_list),\n",
    "        \"community\": \"AG\",\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"format\": \"JSON\"\n",
    "    }\n",
    "    curr_data = {}\n",
    "\n",
    "    response = requests.get(url, params=parameters)\n",
    "    data = response.json()\n",
    "    try:\n",
    "        for param in param_list:\n",
    "            curr_data[param] = data['properties']['parameter'][param]\n",
    "    except:\n",
    "        print(f\"Error getting data for {year}-{month_str}-{day_str} at {lat},{lon}\")\n",
    "        return None\n",
    "    \n",
    "    return curr_data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": 20,
>>>>>>> 4e687d2c634c322085eee218f4bf4ed521d78180
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GET_WEATHER is True, fetch weather data for each observation, save to weather_data.csv\n",
    "\n",
    "if GET_WEATHER:\n",
    "    \"\"\"\n",
    "    T2M\tTemperature at 2 Meters\n",
    "    RH2M\tRelative Humidity at 2 Meters\n",
    "    T2MDEW\tDew/Frost Point at 2 Meters\n",
    "    PRECTOTCORR\tPrecipitation Corrected\n",
    "    TSOIL1\tSoil Temperatures Layer 1\n",
    "    T2MWET\tWet Bulb Temperature at 2 Meters\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    dataframe = pd.DataFrame(columns=['Datetime','id', 'Temperature', 'Humidity', 'Wind Speed', 'Dew/Frost Point', 'Wet Bulb Temperature', 'Specific Humidity'])\n",
    "\n",
    "    param_list = ['T2M', 'RH2M', 'T2MDEW', 'PRECTOTCORR', 'TSOIL1', 'T2MWET']\n",
    "\n",
    "    for i, row in observations_df.iterrows():\n",
    "        weather_data = get_general_weather(row['longitude'], row['latitude'], row['day'], row['month'], row['year'], param_list)\n",
    "        if weather_data is None:\n",
    "            for j in range(3):\n",
    "                weather_data = get_general_weather(row['longitude'], row['latitude'], row['day'], row['month'], row['year'], param_list)\n",
    "                if weather_data is not None:\n",
    "                    break\n",
    "        if weather_data is None:    \n",
    "            continue\n",
    "        dates = list(weather_data['T2M'].keys())\n",
    "        id_vals = [row['id']] * len(dates)\n",
    "        temp_values = list(weather_data['T2M'].values())\n",
    "        humidity_values = list(weather_data['RH2M'].values())\n",
    "        dew_frost_values = list(weather_data['T2MDEW'].values())\n",
    "        precipitation_values = list(weather_data['PRECTOTCORR'].values())\n",
    "        soil_temperature_values = list(weather_data['TSOIL1'].values())\n",
    "        wet_bulb_values = list(weather_data['T2MWET'].values())\n",
    "        curr_df = pd.DataFrame({\n",
    "            'Datetime': dates,\n",
    "            'id': id_vals,\n",
    "            'Temperature': temp_values,\n",
    "            'Humidity': humidity_values,\n",
    "            'Precipitation': precipitation_values,\n",
    "            'Dew/Frost Point': dew_frost_values,\n",
    "            'Wet Bulb Temperature': wet_bulb_values,\n",
    "            'Soil Temperature': soil_temperature_values\n",
    "        })\n",
    "        \n",
    "        weather_vars = ['Temperature', 'Humidity', 'Precipitation', 'Dew/Frost Point', 'Wet Bulb Temperature', 'Soil Temperature']\n",
    "        \n",
    "        dataframe = pd.concat([dataframe, curr_df], ignore_index=True)\n",
    "        # Print progress every 10 rows\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processed {i}\")\n",
    "        \n",
    "    dataframe.to_csv('weather_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_string</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>PowderyMildew</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48688154</td>\n",
       "      <td>2020-06-06T14:17:01-04:00</td>\n",
       "      <td>[-73.9520673641, 40.7700205967]</td>\n",
       "      <td>True</td>\n",
       "      <td>-73.952067</td>\n",
       "      <td>40.770021</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116476822</td>\n",
       "      <td>2022-05-10T16:37:09-04:00</td>\n",
       "      <td>[-73.95191313710001, 40.7701800205]</td>\n",
       "      <td>True</td>\n",
       "      <td>-73.951913</td>\n",
       "      <td>40.770180</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169576529</td>\n",
       "      <td>2023-06-26T09:10:01+02:00</td>\n",
       "      <td>[8.80802725, 50.8119201389]</td>\n",
       "      <td>True</td>\n",
       "      <td>8.808027</td>\n",
       "      <td>50.811920</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206356226</td>\n",
       "      <td>2024-04-09T19:08:00-04:00</td>\n",
       "      <td>[-76.3073433611, 38.9860498889]</td>\n",
       "      <td>True</td>\n",
       "      <td>-76.307343</td>\n",
       "      <td>38.986050</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162498461</td>\n",
       "      <td>2023-05-19T16:44:24+02:00</td>\n",
       "      <td>[12.9216153547, 48.6943073404]</td>\n",
       "      <td>True</td>\n",
       "      <td>12.921615</td>\n",
       "      <td>48.694307</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                date_string  ... month  day\n",
       "0   48688154  2020-06-06T14:17:01-04:00  ...     6    6\n",
       "1  116476822  2022-05-10T16:37:09-04:00  ...     5   10\n",
       "2  169576529  2023-06-26T09:10:01+02:00  ...     6   26\n",
       "3  206356226  2024-04-09T19:08:00-04:00  ...     4    9\n",
       "4  162498461  2023-05-19T16:44:24+02:00  ...     5   19\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 120  features\n"
     ]
    }
   ],
   "source": [
    "# Load the weather data if not already loaded\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the weather data\n",
    "weather_df = pd.read_csv('weather_data.csv')\n",
    "\n",
    "# convert datetime to same format as observations_df\n",
    "weather_df['Datetime'] = pd.to_datetime(weather_df['Datetime'], format='%Y%m%d%H')\n",
    "weather_df['Date'] = weather_df['Datetime'].dt.date\n",
    "\n",
    "# Use same format as weather_df\n",
    "observations_df['Date'] = pd.to_datetime(observations_df[['year', 'month', 'day']])\n",
    "\n",
    "# Group by id and Date to find all unique days per ID\n",
    "day_indices = weather_df.groupby(['id', 'Date']).first().reset_index()\n",
    "\n",
    "# make dict of observation ID with original date\n",
    "observation_dates = {}\n",
    "for _, row in observations_df.iterrows():\n",
    "    observation_dates[row['id']] = row['Date']\n",
    "\n",
    "# Calculate difference between observation date and weather date\n",
    "def get_relative_day(row):\n",
    "    obs_date = observation_dates.get(row['id'])\n",
    "    this_date = pd.to_datetime(row['Date'])\n",
    "    difference = (this_date - obs_date).days\n",
    "    return difference\n",
    "\n",
    "# Apply the function to get relative day\n",
    "day_indices['RelativeDay'] = day_indices.apply(get_relative_day, axis=1)\n",
    "\n",
    "# Add relative day to weather_df\n",
    "day_map = day_indices.set_index(['id', 'Date'])['RelativeDay']\n",
    "weather_df['RelativeDay'] = weather_df.set_index(['id', 'Date']).index.map(day_map)\n",
    "\n",
    "# Variables to calculate aggregations for\n",
    "weather_vars = ['Temperature', 'Humidity', 'Precipitation', 'Dew/Frost Point', 'Wet Bulb Temperature', 'Soil Temperature']\n",
    "\n",
    "# Time windows to aggregate over (days before and after the observation day)\n",
    "time_windows = {\n",
    "    'day_of': (0, 0),\n",
    "    'day_before_after': (-1, 0),\n",
    "    'two_days': (-2, 0),\n",
    "    'three_days': (-3, 0),\n",
    "    'one_week': (-7, 0),\n",
    "    'two_week': (-14, 0)\n",
    "}\n",
    "\n",
    "# Function to calculate aggregates given ID and time window\n",
    "def calculate_aggregates(weather_subset, var_name, window_name, start_day, end_day):\n",
    "    # Filter data for given time window\n",
    "    window_data = weather_subset[(weather_subset['RelativeDay'] >= start_day) & (weather_subset['RelativeDay'] <= end_day)]\n",
    "    \n",
    "    # Calculate aggregate and return as a series\n",
    "    result = pd.Series({\n",
    "        f\"{var_name}_{window_name}_mean\": window_data[var_name].mean(),\n",
    "        f\"{var_name}_{window_name}_min\": window_data[var_name].min(),\n",
    "        f\"{var_name}_{window_name}_max\": window_data[var_name].max(),\n",
    "        f\"{var_name}_{window_name}_median\": window_data[var_name].median()\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Create empty DataFrame to store results\n",
    "all_features = []\n",
    "result_rows = []\n",
    "\n",
    "# For each observation row, calculate all aggregate weather data\n",
    "for id_val in observations_df['id'].unique():\n",
    "    id_weather = weather_df[weather_df['id'] == id_val]\n",
    "        \n",
    "    # Dictionary to store aggregated values for this ID\n",
    "    id_features = {'id': id_val}\n",
    "    \n",
    "    # Iterate over all weather data variables\n",
    "    for var in weather_vars:\n",
    "        # iterate over all items in time_windows\n",
    "        for window_name, (start_day, end_day) in time_windows.items():\n",
    "            aggs = calculate_aggregates(id_weather, var, window_name, start_day, end_day)\n",
    "            id_features.update(aggs)\n",
    "            \n",
    "            # Add feature names to our list (only once)\n",
    "            if id_val == observations_df['id'].unique()[0]:\n",
    "                all_features.extend(aggs.index.tolist())\n",
    "    \n",
    "    result_rows.append(id_features)\n",
    "\n",
    "# Create DataFrame from results\n",
    "aggregated_features = pd.DataFrame(result_rows)\n",
    "\n",
    "# Merge with the original observations dataframe\n",
    "observations_df = observations_df.merge(aggregated_features, on='id', how='left')\n",
    "\n",
    "# Create list of feature names\n",
    "weather_feature_names = all_features\n",
    "\n",
    "print(f\"Created {len(weather_feature_names)}  features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to decrease relationships between variables (such as the connections and potential spurrious correlations between powdery mildew and date_string, month, and day) we can combine this date information into one number: the day of the calendar year 1-365."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_string</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>PowderyMildew</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Temperature_day_of_mean</th>\n",
       "      <th>Temperature_day_of_min</th>\n",
       "      <th>Temperature_day_of_max</th>\n",
       "      <th>Temperature_day_of_median</th>\n",
       "      <th>Temperature_day_before_after_mean</th>\n",
       "      <th>Temperature_day_before_after_min</th>\n",
       "      <th>Temperature_day_before_after_max</th>\n",
       "      <th>Temperature_day_before_after_median</th>\n",
       "      <th>Temperature_three_days_mean</th>\n",
       "      <th>Temperature_three_days_min</th>\n",
       "      <th>Temperature_three_days_max</th>\n",
       "      <th>Temperature_three_days_median</th>\n",
       "      <th>Temperature_one_week_mean</th>\n",
       "      <th>Temperature_one_week_min</th>\n",
       "      <th>Temperature_one_week_max</th>\n",
       "      <th>Temperature_one_week_median</th>\n",
       "      <th>Temperature_two_weeks_mean</th>\n",
       "      <th>Temperature_two_weeks_min</th>\n",
       "      <th>Temperature_two_weeks_max</th>\n",
       "      <th>Temperature_two_weeks_median</th>\n",
       "      <th>Humidity_day_of_mean</th>\n",
       "      <th>Humidity_day_of_min</th>\n",
       "      <th>Humidity_day_of_max</th>\n",
       "      <th>Humidity_day_of_median</th>\n",
       "      <th>Humidity_day_before_after_mean</th>\n",
       "      <th>Humidity_day_before_after_min</th>\n",
       "      <th>Humidity_day_before_after_max</th>\n",
       "      <th>Humidity_day_before_after_median</th>\n",
       "      <th>Humidity_three_days_mean</th>\n",
       "      <th>Humidity_three_days_min</th>\n",
       "      <th>...</th>\n",
       "      <th>Wet Bulb Temperature_day_of_min</th>\n",
       "      <th>Wet Bulb Temperature_day_of_max</th>\n",
       "      <th>Wet Bulb Temperature_day_of_median</th>\n",
       "      <th>Wet Bulb Temperature_day_before_after_mean</th>\n",
       "      <th>Wet Bulb Temperature_day_before_after_min</th>\n",
       "      <th>Wet Bulb Temperature_day_before_after_max</th>\n",
       "      <th>Wet Bulb Temperature_day_before_after_median</th>\n",
       "      <th>Wet Bulb Temperature_three_days_mean</th>\n",
       "      <th>Wet Bulb Temperature_three_days_min</th>\n",
       "      <th>Wet Bulb Temperature_three_days_max</th>\n",
       "      <th>Wet Bulb Temperature_three_days_median</th>\n",
       "      <th>Wet Bulb Temperature_one_week_mean</th>\n",
       "      <th>Wet Bulb Temperature_one_week_min</th>\n",
       "      <th>Wet Bulb Temperature_one_week_max</th>\n",
       "      <th>Wet Bulb Temperature_one_week_median</th>\n",
       "      <th>Wet Bulb Temperature_two_weeks_mean</th>\n",
       "      <th>Wet Bulb Temperature_two_weeks_min</th>\n",
       "      <th>Wet Bulb Temperature_two_weeks_max</th>\n",
       "      <th>Wet Bulb Temperature_two_weeks_median</th>\n",
       "      <th>Specific Humidity_day_of_mean</th>\n",
       "      <th>Specific Humidity_day_of_min</th>\n",
       "      <th>Specific Humidity_day_of_max</th>\n",
       "      <th>Specific Humidity_day_of_median</th>\n",
       "      <th>Specific Humidity_day_before_after_mean</th>\n",
       "      <th>Specific Humidity_day_before_after_min</th>\n",
       "      <th>Specific Humidity_day_before_after_max</th>\n",
       "      <th>Specific Humidity_day_before_after_median</th>\n",
       "      <th>Specific Humidity_three_days_mean</th>\n",
       "      <th>Specific Humidity_three_days_min</th>\n",
       "      <th>Specific Humidity_three_days_max</th>\n",
       "      <th>Specific Humidity_three_days_median</th>\n",
       "      <th>Specific Humidity_one_week_mean</th>\n",
       "      <th>Specific Humidity_one_week_min</th>\n",
       "      <th>Specific Humidity_one_week_max</th>\n",
       "      <th>Specific Humidity_one_week_median</th>\n",
       "      <th>Specific Humidity_two_weeks_mean</th>\n",
       "      <th>Specific Humidity_two_weeks_min</th>\n",
       "      <th>Specific Humidity_two_weeks_max</th>\n",
       "      <th>Specific Humidity_two_weeks_median</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48688154</td>\n",
       "      <td>2020-06-06T14:17:01-04:00</td>\n",
       "      <td>[-73.9520673641, 40.7700205967]</td>\n",
       "      <td>True</td>\n",
       "      <td>-73.952067</td>\n",
       "      <td>40.770021</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>22.469583</td>\n",
       "      <td>16.48</td>\n",
       "      <td>28.06</td>\n",
       "      <td>21.620</td>\n",
       "      <td>20.618611</td>\n",
       "      <td>14.27</td>\n",
       "      <td>28.06</td>\n",
       "      <td>19.915</td>\n",
       "      <td>20.555774</td>\n",
       "      <td>11.76</td>\n",
       "      <td>28.06</td>\n",
       "      <td>20.230</td>\n",
       "      <td>19.374278</td>\n",
       "      <td>6.70</td>\n",
       "      <td>28.06</td>\n",
       "      <td>19.165</td>\n",
       "      <td>19.374278</td>\n",
       "      <td>6.70</td>\n",
       "      <td>28.06</td>\n",
       "      <td>19.165</td>\n",
       "      <td>78.492917</td>\n",
       "      <td>61.95</td>\n",
       "      <td>98.68</td>\n",
       "      <td>75.155</td>\n",
       "      <td>79.419167</td>\n",
       "      <td>48.34</td>\n",
       "      <td>98.68</td>\n",
       "      <td>80.090</td>\n",
       "      <td>78.190476</td>\n",
       "      <td>43.83</td>\n",
       "      <td>...</td>\n",
       "      <td>15.12</td>\n",
       "      <td>24.15</td>\n",
       "      <td>20.000</td>\n",
       "      <td>18.601528</td>\n",
       "      <td>13.71</td>\n",
       "      <td>24.15</td>\n",
       "      <td>18.035</td>\n",
       "      <td>18.370655</td>\n",
       "      <td>11.53</td>\n",
       "      <td>24.15</td>\n",
       "      <td>18.230</td>\n",
       "      <td>16.997639</td>\n",
       "      <td>5.80</td>\n",
       "      <td>24.15</td>\n",
       "      <td>17.495</td>\n",
       "      <td>16.997639</td>\n",
       "      <td>5.80</td>\n",
       "      <td>24.15</td>\n",
       "      <td>17.495</td>\n",
       "      <td>13.259167</td>\n",
       "      <td>9.84</td>\n",
       "      <td>15.60</td>\n",
       "      <td>13.185</td>\n",
       "      <td>12.034583</td>\n",
       "      <td>8.31</td>\n",
       "      <td>15.60</td>\n",
       "      <td>12.710</td>\n",
       "      <td>11.730476</td>\n",
       "      <td>7.36</td>\n",
       "      <td>15.62</td>\n",
       "      <td>12.215</td>\n",
       "      <td>10.758667</td>\n",
       "      <td>5.23</td>\n",
       "      <td>16.13</td>\n",
       "      <td>10.620</td>\n",
       "      <td>10.758667</td>\n",
       "      <td>5.23</td>\n",
       "      <td>16.13</td>\n",
       "      <td>10.620</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116476822</td>\n",
       "      <td>2022-05-10T16:37:09-04:00</td>\n",
       "      <td>[-73.95191313710001, 40.7701800205]</td>\n",
       "      <td>True</td>\n",
       "      <td>-73.951913</td>\n",
       "      <td>40.770180</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>11.411667</td>\n",
       "      <td>3.99</td>\n",
       "      <td>19.20</td>\n",
       "      <td>10.705</td>\n",
       "      <td>12.023056</td>\n",
       "      <td>3.39</td>\n",
       "      <td>22.16</td>\n",
       "      <td>12.210</td>\n",
       "      <td>12.644881</td>\n",
       "      <td>3.39</td>\n",
       "      <td>23.85</td>\n",
       "      <td>11.950</td>\n",
       "      <td>13.965139</td>\n",
       "      <td>3.39</td>\n",
       "      <td>24.53</td>\n",
       "      <td>13.710</td>\n",
       "      <td>13.965139</td>\n",
       "      <td>3.39</td>\n",
       "      <td>24.53</td>\n",
       "      <td>13.710</td>\n",
       "      <td>58.924167</td>\n",
       "      <td>40.80</td>\n",
       "      <td>75.46</td>\n",
       "      <td>64.990</td>\n",
       "      <td>63.393472</td>\n",
       "      <td>38.03</td>\n",
       "      <td>95.52</td>\n",
       "      <td>64.310</td>\n",
       "      <td>72.965060</td>\n",
       "      <td>38.03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.02</td>\n",
       "      <td>12.80</td>\n",
       "      <td>6.985</td>\n",
       "      <td>8.415972</td>\n",
       "      <td>2.02</td>\n",
       "      <td>18.38</td>\n",
       "      <td>7.865</td>\n",
       "      <td>10.067440</td>\n",
       "      <td>2.02</td>\n",
       "      <td>20.30</td>\n",
       "      <td>8.985</td>\n",
       "      <td>11.951806</td>\n",
       "      <td>2.02</td>\n",
       "      <td>21.04</td>\n",
       "      <td>11.875</td>\n",
       "      <td>11.951806</td>\n",
       "      <td>2.02</td>\n",
       "      <td>21.04</td>\n",
       "      <td>11.875</td>\n",
       "      <td>4.793333</td>\n",
       "      <td>3.75</td>\n",
       "      <td>6.34</td>\n",
       "      <td>4.620</td>\n",
       "      <td>5.586389</td>\n",
       "      <td>3.75</td>\n",
       "      <td>11.24</td>\n",
       "      <td>4.565</td>\n",
       "      <td>6.826548</td>\n",
       "      <td>3.75</td>\n",
       "      <td>12.47</td>\n",
       "      <td>5.740</td>\n",
       "      <td>7.963972</td>\n",
       "      <td>3.75</td>\n",
       "      <td>13.07</td>\n",
       "      <td>7.720</td>\n",
       "      <td>7.963972</td>\n",
       "      <td>3.75</td>\n",
       "      <td>13.07</td>\n",
       "      <td>7.720</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>169576529</td>\n",
       "      <td>2023-06-26T09:10:01+02:00</td>\n",
       "      <td>[8.80802725, 50.8119201389]</td>\n",
       "      <td>True</td>\n",
       "      <td>8.808027</td>\n",
       "      <td>50.811920</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>2023-06-26</td>\n",
       "      <td>18.713750</td>\n",
       "      <td>12.89</td>\n",
       "      <td>22.48</td>\n",
       "      <td>18.470</td>\n",
       "      <td>18.577778</td>\n",
       "      <td>10.73</td>\n",
       "      <td>26.62</td>\n",
       "      <td>18.260</td>\n",
       "      <td>18.221429</td>\n",
       "      <td>10.51</td>\n",
       "      <td>26.62</td>\n",
       "      <td>18.225</td>\n",
       "      <td>18.380028</td>\n",
       "      <td>10.14</td>\n",
       "      <td>26.62</td>\n",
       "      <td>18.285</td>\n",
       "      <td>18.380028</td>\n",
       "      <td>10.14</td>\n",
       "      <td>26.62</td>\n",
       "      <td>18.285</td>\n",
       "      <td>71.524167</td>\n",
       "      <td>54.26</td>\n",
       "      <td>91.38</td>\n",
       "      <td>68.545</td>\n",
       "      <td>71.155556</td>\n",
       "      <td>51.29</td>\n",
       "      <td>96.90</td>\n",
       "      <td>69.065</td>\n",
       "      <td>73.733690</td>\n",
       "      <td>51.29</td>\n",
       "      <td>...</td>\n",
       "      <td>12.22</td>\n",
       "      <td>19.11</td>\n",
       "      <td>15.805</td>\n",
       "      <td>15.746944</td>\n",
       "      <td>10.50</td>\n",
       "      <td>21.31</td>\n",
       "      <td>14.895</td>\n",
       "      <td>15.670833</td>\n",
       "      <td>10.32</td>\n",
       "      <td>21.31</td>\n",
       "      <td>15.300</td>\n",
       "      <td>15.982500</td>\n",
       "      <td>9.28</td>\n",
       "      <td>22.54</td>\n",
       "      <td>15.660</td>\n",
       "      <td>15.982500</td>\n",
       "      <td>9.28</td>\n",
       "      <td>22.54</td>\n",
       "      <td>15.660</td>\n",
       "      <td>9.894167</td>\n",
       "      <td>8.45</td>\n",
       "      <td>11.66</td>\n",
       "      <td>9.745</td>\n",
       "      <td>9.681944</td>\n",
       "      <td>7.69</td>\n",
       "      <td>13.33</td>\n",
       "      <td>9.485</td>\n",
       "      <td>9.787381</td>\n",
       "      <td>7.41</td>\n",
       "      <td>13.33</td>\n",
       "      <td>9.705</td>\n",
       "      <td>10.219306</td>\n",
       "      <td>6.80</td>\n",
       "      <td>15.44</td>\n",
       "      <td>9.895</td>\n",
       "      <td>10.219306</td>\n",
       "      <td>6.80</td>\n",
       "      <td>15.44</td>\n",
       "      <td>9.895</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206356226</td>\n",
       "      <td>2024-04-09T19:08:00-04:00</td>\n",
       "      <td>[-76.3073433611, 38.9860498889]</td>\n",
       "      <td>True</td>\n",
       "      <td>-76.307343</td>\n",
       "      <td>38.986050</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>15.145833</td>\n",
       "      <td>8.42</td>\n",
       "      <td>22.56</td>\n",
       "      <td>14.760</td>\n",
       "      <td>14.839583</td>\n",
       "      <td>6.65</td>\n",
       "      <td>22.71</td>\n",
       "      <td>15.045</td>\n",
       "      <td>13.485119</td>\n",
       "      <td>2.59</td>\n",
       "      <td>22.71</td>\n",
       "      <td>14.235</td>\n",
       "      <td>12.848167</td>\n",
       "      <td>2.59</td>\n",
       "      <td>25.04</td>\n",
       "      <td>12.510</td>\n",
       "      <td>12.848167</td>\n",
       "      <td>2.59</td>\n",
       "      <td>25.04</td>\n",
       "      <td>12.510</td>\n",
       "      <td>82.803750</td>\n",
       "      <td>51.07</td>\n",
       "      <td>100.00</td>\n",
       "      <td>88.150</td>\n",
       "      <td>80.454028</td>\n",
       "      <td>50.62</td>\n",
       "      <td>100.00</td>\n",
       "      <td>83.205</td>\n",
       "      <td>80.435298</td>\n",
       "      <td>50.62</td>\n",
       "      <td>...</td>\n",
       "      <td>9.06</td>\n",
       "      <td>17.29</td>\n",
       "      <td>13.930</td>\n",
       "      <td>13.054861</td>\n",
       "      <td>5.45</td>\n",
       "      <td>18.88</td>\n",
       "      <td>13.380</td>\n",
       "      <td>11.722024</td>\n",
       "      <td>2.13</td>\n",
       "      <td>18.88</td>\n",
       "      <td>12.720</td>\n",
       "      <td>11.100556</td>\n",
       "      <td>2.13</td>\n",
       "      <td>21.07</td>\n",
       "      <td>10.765</td>\n",
       "      <td>11.100556</td>\n",
       "      <td>2.13</td>\n",
       "      <td>21.07</td>\n",
       "      <td>10.765</td>\n",
       "      <td>8.686667</td>\n",
       "      <td>7.40</td>\n",
       "      <td>10.18</td>\n",
       "      <td>8.925</td>\n",
       "      <td>8.422361</td>\n",
       "      <td>5.00</td>\n",
       "      <td>11.44</td>\n",
       "      <td>8.925</td>\n",
       "      <td>7.882917</td>\n",
       "      <td>4.25</td>\n",
       "      <td>11.84</td>\n",
       "      <td>7.595</td>\n",
       "      <td>7.551944</td>\n",
       "      <td>4.25</td>\n",
       "      <td>13.70</td>\n",
       "      <td>7.070</td>\n",
       "      <td>7.551944</td>\n",
       "      <td>4.25</td>\n",
       "      <td>13.70</td>\n",
       "      <td>7.070</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162498461</td>\n",
       "      <td>2023-05-19T16:44:24+02:00</td>\n",
       "      <td>[12.9216153547, 48.6943073404]</td>\n",
       "      <td>True</td>\n",
       "      <td>12.921615</td>\n",
       "      <td>48.694307</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>2023-05-19</td>\n",
       "      <td>12.145417</td>\n",
       "      <td>4.62</td>\n",
       "      <td>17.35</td>\n",
       "      <td>12.930</td>\n",
       "      <td>12.539444</td>\n",
       "      <td>2.96</td>\n",
       "      <td>21.59</td>\n",
       "      <td>13.415</td>\n",
       "      <td>13.582024</td>\n",
       "      <td>2.96</td>\n",
       "      <td>24.76</td>\n",
       "      <td>13.355</td>\n",
       "      <td>13.265250</td>\n",
       "      <td>2.96</td>\n",
       "      <td>24.76</td>\n",
       "      <td>12.900</td>\n",
       "      <td>13.265250</td>\n",
       "      <td>2.96</td>\n",
       "      <td>24.76</td>\n",
       "      <td>12.900</td>\n",
       "      <td>78.535417</td>\n",
       "      <td>62.84</td>\n",
       "      <td>95.40</td>\n",
       "      <td>79.405</td>\n",
       "      <td>77.980972</td>\n",
       "      <td>52.73</td>\n",
       "      <td>98.71</td>\n",
       "      <td>80.655</td>\n",
       "      <td>78.192798</td>\n",
       "      <td>52.15</td>\n",
       "      <td>...</td>\n",
       "      <td>4.29</td>\n",
       "      <td>14.16</td>\n",
       "      <td>11.240</td>\n",
       "      <td>10.525278</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17.40</td>\n",
       "      <td>10.380</td>\n",
       "      <td>11.553274</td>\n",
       "      <td>2.75</td>\n",
       "      <td>19.61</td>\n",
       "      <td>11.415</td>\n",
       "      <td>11.453917</td>\n",
       "      <td>2.75</td>\n",
       "      <td>19.61</td>\n",
       "      <td>11.125</td>\n",
       "      <td>11.453917</td>\n",
       "      <td>2.75</td>\n",
       "      <td>19.61</td>\n",
       "      <td>11.125</td>\n",
       "      <td>7.190833</td>\n",
       "      <td>5.22</td>\n",
       "      <td>8.89</td>\n",
       "      <td>7.755</td>\n",
       "      <td>7.349722</td>\n",
       "      <td>4.71</td>\n",
       "      <td>10.33</td>\n",
       "      <td>7.475</td>\n",
       "      <td>7.893631</td>\n",
       "      <td>4.71</td>\n",
       "      <td>11.19</td>\n",
       "      <td>8.020</td>\n",
       "      <td>7.895417</td>\n",
       "      <td>4.71</td>\n",
       "      <td>11.56</td>\n",
       "      <td>7.625</td>\n",
       "      <td>7.895417</td>\n",
       "      <td>4.71</td>\n",
       "      <td>11.56</td>\n",
       "      <td>7.625</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  ... day_of_year\n",
       "0   48688154  ...         158\n",
       "1  116476822  ...         130\n",
       "2  169576529  ...         177\n",
       "3  206356226  ...         100\n",
       "4  162498461  ...         139\n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate day of year from year, month, and day\n",
    "from datetime import datetime\n",
    "\n",
    "# Add day of year as a feature to observations_df\n",
    "observations_df['day_of_year'] = observations_df.apply(\n",
    "    lambda row: datetime(row['year'], row['month'], row['day']).timetuple().tm_yday, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop rows with NaN values\n",
    "observations_df = observations_df.dropna()\n",
    "\n",
    "# Display the updated DataFrame\n",
    "observations_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to build a regression tree using this updated data frame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7230769230769231\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.72      0.72        32\n",
      "        True       0.73      0.73      0.73        33\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.72      0.72      0.72        65\n",
      "weighted avg       0.72      0.72      0.72        65\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAIjCAYAAACTRapjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8tUlEQVR4nO3dCZxN9f/H8c8ZxhjbMLLGMAoRIVQiS8mSbC3aUVT8LDGWjCIKU1psiVZC2sgSRXbZ+mUZLWSd0kJEaAZju//H5/t73PnPHYM709y5d+739fw/zn/mnnvuOd8z/YaP93c5jsvlcgkAAACsEeLvBgAAACB7UQACAABYhgIQAADAMhSAAAAAlqEABAAAsAwFIAAAgGUoAAEAACxDAQgAAGAZCkAAAADLUAACuKRdu3ZJs2bNJCIiQhzHkblz52bp+X/++Wdz3qlTp2bpeXOyxo0bmw0AfIUCEMgB9uzZI08++aRUqFBB8ubNK4UKFZL69evLuHHj5OTJkz69dqdOneT777+XkSNHyvTp06VOnToSLDp37myKT/15pvdz1OJX39ftlVdeyfD5//jjDxk2bJjEx8dnUYsBIGvkzqLzAPCRhQsXyr333ithYWHSsWNHqVatmpw+fVrWrFkjAwYMkB9//FHeeustn1xbi6L169fLM888Iz179vTJNcqVK2euExoaKv6QO3duOXHihHz++efSoUMHj/c++OADU3CfOnUqU+fWAnD48OFSvnx5qVmzptef++qrrzJ1PQDwFgUgEMASEhLk/vvvN0XS8uXLpVSpUinv9ejRQ3bv3m0KRF85dOiQ+Vq4cGGfXUPTNS2y/EULa01TP/zwwwsKwJkzZ0qrVq1k9uzZ2dIWLUTz5csnefLkyZbrAbAXXcBAABs9erQkJibKu+++61H8uV199dXy1FNPpbw+e/asvPDCC3LVVVeZwkaTp8GDB0tycrLH53T/nXfeaVLEG264wRRg2r08bdq0lGO061ILT6VJoxZq+jl316n7+9T0M3pcakuWLJEGDRqYIrJAgQJSuXJl06bLjQHUgveWW26R/Pnzm8+2bdtWtm/fnu71tBDWNulxOlbx0UcfNcWUtx588EH58ssv5ejRoyn7vv32W9MFrO+ldeTIEenfv79Ur17d3JN2Ibds2VK2bt2acszKlSulbt265nttj7sr2X2fOsZP09xNmzZJw4YNTeHn/rmkHQOo3fD63yjt/Tdv3lyKFClikkYAyAgKQCCAabekFmY333yzV8d37dpVhg4dKtdff72MGTNGGjVqJHFxcSZFTEuLpnvuuUduv/12efXVV00hoUWUdimru+66y5xDPfDAA2b839ixYzPUfj2XFppagD7//PPmOm3atJG1a9de8nNLly41xc3BgwdNkRcTEyPr1q0zSZ0WjGlpcvfPP/+Ye9XvtcjSrldv6b1qcfbZZ595pH/XXHON+VmmtXfvXjMZRu/ttddeMwWyjpPUn7e7GKtSpYq5Z/XEE0+Yn59uWuy5HT582BSO2j2sP9smTZqk2z4d61msWDFTCJ47d87se/PNN01X8YQJE6R06dJe3ysAGC4AAenYsWMu/RVt27atV8fHx8eb47t27eqxv3///mb/8uXLU/aVK1fO7Fu9enXKvoMHD7rCwsJc/fr1S9mXkJBgjnv55Zc9ztmpUydzjrSee+45c7zbmDFjzOtDhw5dtN3ua0yZMiVlX82aNV3Fixd3HT58OGXf1q1bXSEhIa6OHTtecL3HHnvM45zt27d3FS1a9KLXTH0f+fPnN9/fc889rttuu818f+7cOVfJkiVdw4cPT/dncOrUKXNM2vvQn9/zzz+fsu/bb7+94N7cGjVqZN6bPHlyuu/pltrixYvN8SNGjHDt3bvXVaBAAVe7du0ue48AkB4SQCBAHT9+3HwtWLCgV8d/8cUX5qumZan169fPfE07VrBq1aqmi9VNEybtntV0K6u4xw7OmzdPzp8/79Vn9u/fb2bNahoZGRmZsv+6664zaaX7PlPr1q2bx2u9L03X3D9Db2hXr3bbHjhwwHQ/69f0un+Vdq+HhPzvj09N5PRa7u7tzZs3e31NPY92D3tDl+LRmeCaKmpiqV3CmgICQGZQAAIBSseVKe3a9MYvv/xiihIdF5hayZIlTSGm76cWFRV1wTm0G/jvv/+WrHLfffeZblvtmi5RooTpiv7kk08uWQy626nFVFrarfrXX39JUlLSJe9F70Nl5F7uuOMOU2x//PHHZvavjt9L+7N00/Zr93jFihVNEXfFFVeYAvq7776TY8eOeX3NK6+8MkMTPnQpGi2KtUAeP368FC9e3OvPAkBqFIBAABeAOrbrhx9+yNDn0k7CuJhcuXKlu9/lcmX6Gu7xaW7h4eGyevVqM6bvkUceMQWSFoWa5KU99t/4N/fipoWcJmvvv/++zJkz56Lpnxo1apRJWnU834wZM2Tx4sVmssu1117rddLp/vlkxJYtW8y4SKVjDgEgsygAgQCmkwx0EWhdi+9ydMauFh86czW1P//808xudc/ozQqasKWeMeuWNmVUmkredtttZrLEtm3bzILS2sW6YsWKi96H2rFjxwXv/fTTTyZt05nBvqBFnxZZmrqmN3HGbdasWWbChs7O1uO0e7Zp06YX/Ey8Lca9oamndhdr171OKtEZ4jpTGQAygwIQCGADBw40xY52oWohl5YWhzpD1N2FqdLO1NXCS+l6dllFl5nRrk5N9FKP3dPkLO1yKWm5F0ROuzSNmy53o8doEpe6oNIkVGe9uu/TF7So02V0Xn/9ddN1fqnEMW26+Omnn8rvv//usc9dqKZXLGfU008/Lfv27TM/F/1vqsvw6Kzgi/0cAeBSWAgaCGBaaOlyJNptquPfUj8JRJdF0aJDJ0uoGjVqmIJAnwqiBYcuSfLf//7XFAzt2rW76BIjmaGplxYk7du3l969e5s19yZNmiSVKlXymAShExa0C1iLT032tPvyjTfekDJlypi1AS/m5ZdfNsuj1KtXT7p06WKeFKLLnegaf7osjK9oWvnss896lczqvWkip0v0aHesjhvUJXvS/vfT8ZeTJ0824wu1ILzxxhslOjo6Q+3SxFR/bs8991zKsjRTpkwxawUOGTLEpIEAkCHpzg0GEFB27tzpevzxx13ly5d35cmTx1WwYEFX/fr1XRMmTDBLkridOXPGLF0SHR3tCg0NdZUtW9YVGxvrcYzSJVxatWp12eVHLrYMjPrqq69c1apVM+2pXLmya8aMGRcsA7Ns2TKzjE3p0qXNcfr1gQceMPeT9hppl0pZunSpucfw8HBXoUKFXK1bt3Zt27bN4xj39dIuM6Pn0v16bm+XgbmYiy0Do8vllCpVyrRP27l+/fp0l2+ZN2+eq2rVqq7cuXN73Kced+2116Z7zdTnOX78uPnvdf3115v/vqn17dvXLI2j1waAjHD0/2WsZAQAAEBOxhhAAAAAy1AAAgAAWIYCEAAAwDIUgAAAAAEiLi7OPIlIVw7Qp/3oKg7prYuqdBqHrpiga47OnTs3Q9ehAAQAAAgQq1atkh49esiGDRvME4bOnDljFptP+whM97qvmV1wnlnAAAAAAerQoUMmCdTCUB8/6abPBNc1STdu3GgW0NeF+DUt9BYLQQMAAPiQPrEn7VN79Pnjul2OPnVJRUZGpuzTxff10ZUTJ0685FOLrCsAw28b5e8mAPCRvxcP9ncTAPhIXj9WJeG1evrs3E+3vUKGDx/usU+f7HO5Jxvp89379Okj9evXN0+Bcuvbt695ClHbtm0z3aagLAABAAACRWxsrMTExHjs8yb907GA+hz0NWvWpOybP3++eTzkli1b/lWbKAABAAAc382L9ba7N7WePXvKggULzPPU9fnpblr87dmzxzxnPLW7775bbrnlFlm5cqVX56cABAAAcDI3mzar6dzcXr16mUkdWsxFR0d7vD9o0CDp2rWrx77q1avLmDFjpHXr1l5fhwIQAAAgQGi378yZM2XevHlmLcADBw6Y/RERERIeHm4mfaQ38SMqKuqCYvFSKAABAACcwFgaedKkSeZr48aNPfZPmTJFOnfunGXXoQAEAAAIEJlZnjkzn6EABAAAcAJjDGB2CYy8EwAAANmGBBAAAMCxKxOz624BAABAAggAACCWjQGkAAQAAHDs6hS1624BAABAAggAACCWdQGTAAIAAFiGBBAAAMCxKxOz624BAABAAggAACCMAQQAAEAwIwEEAABw7MrEKAABAAAcuoABAAAQxEgAAQAAHLsyMbvuFgAAACSAAAAAQgIIAACAYEYCCAAAEMIsYAAAAAQxEkAAAADHrkyMAhAAAMChCxgAAABBjAQQAADAsSsTs+tuAQAAQAIIAAAgjAEEAABAMCMBBAAAcOzKxOy6WwAAAJAAAgAAiGVjACkAAQAAHLs6Re26WwAAAJAAAgAAiGVdwCSAAAAAliEBBAAAcOzKxOy6WwAAAJAAAgAACGMAAQAAEMxIAAEAABy7MjEKQAAAAMeuAtCuuwUAAAAJIAAAgDAJBAAAAMGMBBAAAMCxKxOz624BAABAAggAACCMAQQAAEAwIwEEAABw7MrE7LpbAACAi3UB+2rLgLi4OKlbt64ULFhQihcvLu3atZMdO3akvH/kyBHp1auXVK5cWcLDwyUqKkp69+4tx44dy9B1KAABAAACxKpVq6RHjx6yYcMGWbJkiZw5c0aaNWsmSUlJ5v0//vjDbK+88or88MMPMnXqVFm0aJF06dIlQ9dxXC6XS4JM+G2j/N0EAD7y9+LB/m4CAB/J68eBafnufs9n5z4x+7FMf/bQoUMmCdTCsGHDhuke8+mnn8rDDz9sisTcub37ITIGEAAAwIeSk5PNllpYWJjZLsfdtRsZGXnJYwoVKuR18afoAgYAANZzHMdnm47ri4iI8Nh03+WcP39e+vTpI/Xr15dq1aqle8xff/0lL7zwgjzxxBMZul8SQAAAAB+KjY2VmJgYj33epH86FlDH+a1Zsybd948fPy6tWrWSqlWryrBhwzLUJgpAAAAAx3en9ra7N7WePXvKggULZPXq1VKmTJkL3v/nn3+kRYsWZrbwnDlzJDQ0NEPnpwsYAAAgQOjcXC3+tKhbvny5REdHp5v86czgPHnyyPz58yVv3rwZvg4JIAAAsJ4TII+C027fmTNnyrx580y6d+DAAbNfxw3qun/u4u/EiRMyY8YM81o3VaxYMcmVK5dX16EABAAA1nMCpACcNGmS+dq4cWOP/VOmTJHOnTvL5s2b5ZtvvjH7rr76ao9jEhISpHz58l5dhwIQAAAgQFxueWYtDLNiCWcKQAAAYD0nQBLA7MIkEAAAAMuQAAIAAOs5JIAAAAAIZiSAAAAAjliFBBAAAMAyJIAAAMB6DmMAAQAAEMxIAAEAgPUcyxJACkAAAGA9x7ICkC5gAAAAy5AAAgAA6zkkgAAAAAhmJIAAAACOWIUEEAAAwDIkgAAAwHoOYwABAAAQzEgAAQCA9RzLEkAKQAAAYD3HsgKQLmAAAADLkAACAAA4YhUSQAAAAMuQAAIAAOs5jAEEAABAMCMBBAAA1nNIAAEAABDMSAABAID1HMsSQApAAABgPdsKQLqAAQAALEMCCAAA4IhVSAABAAAsQwIIAACs5zAGEAAAAMEsoArA06dPy44dO+Ts2bP+bgoAALAsAXR8tAWigCgAT5w4IV26dJF8+fLJtddeK/v27TP7e/XqJS+++KK/mwcAABBUAqIAjI2Nla1bt8rKlSslb968KfubNm0qH3/8sV/bBgAAgp9jWQIYEJNA5s6dawq9m266yeMHpWngnj17/No2AABgAUesEhAJ4KFDh6R48eIX7E9KSgrYyhkAACCnCogCsE6dOrJw4cKU1+6i75133pF69er5sWUAAMAGDl3A2W/UqFHSsmVL2bZtm5kBPG7cOPP9unXrZNWqVf5uHgAAQFAJiASwQYMGEh8fb4q/6tWry1dffWW6hNevXy+1a9f2d/MAAECQc0gA/eOqq66St99+29/NAAAACHoBUQBu3rxZQkNDTfqn5s2bJ1OmTJGqVavKsGHDJE+ePP5uIvys/wP1pF2DylIpqqicTD4r32z7TZ55a4Xs+u1IyjET+raUW68vL6WKFpDEk2dkw4+/ybNvr5Cdvx72a9sBZFxSUqJMHD9Oli9bKkeOHJZrqlSVgYMGS7Xq1/m7aQhSToAmdUHdBfzkk0/Kzp07zfd79+6V++67zywK/emnn8rAgQP93TwEgFuui5LJ8zdJo57vy50DP5TcuXLJgtEPSL68oSnHbNm5X54YvUBqPvqWtBn0oejv8oKX7peQELt+qYFgMGzos7J+/ToZ+eJomTXnc6l3c315suuj8ueff/q7aUBQCIgCUIu/mjVrmu+16GvUqJHMnDlTpk6dKrNnz/Z38xAA2sZ+LDMWfy/bf/lLvt970BR6USUipFbFkinHvLcwXtZ+/6vs+/OYxO/6U4ZPWSVlS0RIuRIRfm07gIw5deqULFvylfTtN0Bq16krUeXKSfcevaRsVDn59KOZ/m4egpTDGMDs53K55Pz58+b7pUuXyp133mm+L1u2rPz1119+bh0CUaH8Yebr3/+cSvd9TQY7Nq8hCX/8Lb8dOp7NrQPwb5w7d1bOnTsnYWH/+z1309dbtmz2W7sQ5ByxSu5AWQdwxIgR5tFvuuzLpEmTzP6EhAQpUaLEJT+bnJxsttRc58+KExIQtwYf0H9Mvdyjqaz7/lfZ9vMhj/eeaHO9jHziVikQnkd27DssrQZ+KGfO/u8fFwByhvz5C0iNmrXkrclvSHSFClK06BXy5RcL5Lut8VI2KsrfzQOCQkB0AY8dO9ZMBOnZs6c888wzcvXVV5v9s2bNkptvvvmSn42Li5OIiAiP7ezPrB0YzMb2biHXli8mHUfMveC9j5b9KDc9+a407TNddv12WGYMbS9hobn80k4AmTcybrTpHbq9SUOpW6u6zJwxXVrc0UpCQgLiry0EIceyLmDHpb9hATwOJFeuXGaGcEYSwOJtx5IABqkxvZrJnTdXkqZ9p8svB45d8tjQ3CGyf26M/OfVL+STFduyrY3wrb8XD/Z3E5CNTpw4YWYEFytWXAb06yMnT5yQ1ye95e9mwUfy+vGv7goxX/js3Htfu0MCTUBXSXnz5r3sMTomJO04EYq/4C3+2jSoLM1iZly2+FPuf3nlyUMCCORUuiKEbsePHZP1a9dIn5gB/m4SgpQToEmdr/itUipSpIjXP+wjR/5/rTfYaWzv5nLfbdfKvUNmSeKJ01KiSH6z/1hSspw6fVbKlyos9zSuIss2Jshfx07IlVcUlH4P1JOTp8/I4m/2+Lv5ADJo7ZqvdYaglIuOll/37ZMxr4yW8tEVpG37u/zdNCAo5PbnuD/AW0+2/d8jAZeMedhj/+OjPzfLwySfPiv1q5eVnnffIEUK5JWDfyfJmu/2SZNe0+TQ0RN+ajWAzEpM/EfGj31N/jxwQCIiCstttzeTXk/1veSQIODfcAIkANS5DZ999pn89NNPEh4ebuZCvPTSS1K5cmWPIXL9+vWTjz76yAyDa968ubzxxhuXnTibY8YAZlb4baP83QQAPsIYQCB4+XMM4NX9v/TZuXe/0tLrY1u0aCH333+/1K1bV86ePSuDBw+WH374QbZt2yb58/+v96t79+6ycOFCs16yTn7VSbQ6QWrt2rVeXyfgBstpVXv69GmPfYUKFfJbewAAQPBzAiQCXLRokcdrLfKKFy8umzZtkoYNG8qxY8fk3XffNQ/MuPXWW80x+vjcKlWqyIYNG+Smm27y6joBMZ8+KSnJVK96g1rd6vjA1BsAAIAvOY7vNu2mPX78uMeWdgWTi9GCT0VGRpqvWgieOXPGrJ3sds0110hUVJSsX7/e6/sNiAJQn/e7fPlyswC0zuh95513ZPjw4VK6dGmZNm2av5sHAACQaemtWaz7LkefktanTx+pX7++VKtWzew7cOCA5MmTRwoXLuxxrI7/0/dyVBfw559/bgq9xo0by6OPPiq33HKLWQy6XLly8sEHH8hDDz3k7yYCAIAg5viwCzg2NlZiYmI89qVdwi49PXr0MOP/1qxZk+VtCogEUJd5qVChQsp4P/eyLw0aNJDVq1f7uXUAAACZp8We1jept8sVgDo0bsGCBbJixQopU6ZMyv6SJUuauRJHjx71OP7PP/807+WoAlCLP33ur7sf+5NPPklJBtNGnAAAADlpDGBG6OIsWvzNmTPHDI+Ljo72eL927dpmOaRly5al7NuxY4fs27dP6tWrlzO6gPfu3Svly5c33b5bt26VRo0ayaBBg6R169by+uuvm0GOr732mj+bCAAAkG2021dn+M6bN08KFiyYMq5Pxw3quoD6tUuXLqZLWSeGaJrYq1cvU/x5OwPY7wVgxYoVZf/+/dK3b1/z+r777pPx48ebxQ91louOA7zuuuv82UQAAGCBkJDAWAZGJ8QqnReRmi710rlzZ/P9mDFjzLp/d999t8dC0Bnh14WgtfFa2eryL0orXU0C3eMBM4uFoIHgxULQQPDy50LQVQd/5bNzbxvVTAJNQMwCBgAA8CcnMAJAOwpAnXKddtp1oKzEDQAA7OFYVn/4tQDU3mftz3ZPhdbHwHXr1i3lWXdu+lBkAAAABEEB2KlTJ4/XDz/8sN/aAgAA7OXYFQD6twDUGS0AAADIXkwCAQAA1nMsiwAD4kkgAAAAyD4kgAAAwHoOCSAAAACCGQkgAACwnmNXAEgBCAAA4FhWAdIFDAAAYBkSQAAAYD3HrgCQBBAAAMA2JIAAAMB6jmURIAkgAACAZUgAAQCA9Ry7AkASQAAAANuQAAIAAOs5lkWAJIAAAACWIQEEAADWc+wKACkAAQAAHMsqQLqAAQAALEMCCAAArOfYFQCSAAIAANiGBBAAAFjPsSwCJAEEAACwDAkgAACwnmNXAEgCCAAAYBsSQAAAYD3bxgBSAAIAAOs5dtV/dAEDAADYhgQQAABYz7EsAiQBBAAAsAwJIAAAsJ5DAggAAIBgRgIIAACs59gVAJIAAgAA2IYEEAAAWM+xLAKkAAQAANZz7Kr/6AIGAACwDQkgAACwnmNZBEgCCAAAYBkSQAAAYD3HrgCQBBAAAMA2JIAAAMB6IZZFgCSAAAAAliEBBAAA1nPsCgApAAEAABzLKkC6gAEAACxDAggAAKwXYlcASAIIAAAQSFavXi2tW7eW0qVLm67puXPneryfmJgoPXv2lDJlykh4eLhUrVpVJk+enKFrUAACAADrOY7jsy2jkpKSpEaNGjJx4sR034+JiZFFixbJjBkzZPv27dKnTx9TEM6fP9/ra9AFDAAAEEBatmxptotZt26ddOrUSRo3bmxeP/HEE/Lmm2/Kf//7X2nTpo1X1yABBAAA1nMc323Jycly/Phxj033ZdbNN99s0r7ff/9dXC6XrFixQnbu3CnNmjXz+hwUgAAAAD4UFxcnERERHpvuy6wJEyaYcX86BjBPnjzSokUL013csGFDr89BFzAAALCeI76bBhwbG2vG7aUWFhb2rwrADRs2mBSwXLlyZtJIjx49zKSRpk2benUOCkAAAGC9EB8uA6PF3r8p+FI7efKkDB48WObMmSOtWrUy+6677jqJj4+XV155xesCkC5gAACAHOLMmTNmCwnxLOFy5col58+f9/o8JIAAAMB6TgA9Ck7X+du9e3fK64SEBJPwRUZGSlRUlDRq1EgGDBhg1gDULuBVq1bJtGnT5LXXXvP6GhSAAAAAAWTjxo3SpEmTlNfu8YO69MvUqVPlo48+MuMKH3roITly5IgpAkeOHCndunXz+hoUgAAAwHpO4ASAZn0/Xd7lYkqWLClTpkz5V9dgDCAAAIBlSAABAID1QgIpAswGJIAAAACWIQEEAADWc+wKACkAAQAAHMsqQLqAAQAALEMCCAAArOfYFQCSAAIAANiGBBAAAFgvxLIIkAQQAADAMiSAAADAeo7YhQQQAADAMiSAAADAeo5lYwApAAEAgPVC7Kr/6AIGAACwDQkgAACwnmNZFzAJIAAAgGVIAAEAgPUcuwJAEkAAAADbkAACAADrOZZFgF4VgPPnz/f6hG3atPk37QEAAEAgFIDt2rXzuno+d+7cv20TAABAtgqxKwD0rgA8f/6871sCAADgJ45lXcBMAgEAALBMpiaBJCUlyapVq2Tfvn1y+vRpj/d69+6dVW0DAADIFo7YJcMF4JYtW+SOO+6QEydOmEIwMjJS/vrrL8mXL58UL16cAhAAACDYuoD79u0rrVu3lr///lvCw8Nlw4YN8ssvv0jt2rXllVde8U0rAQAAfCjEcXy2BUUBGB8fL/369ZOQkBDJlSuXJCcnS9myZWX06NEyePBg37QSAAAA/isAQ0NDTfGntMtXxwGqiIgI+fXXX7OuZQAAANnEcXy3BcUYwFq1asm3334rFStWlEaNGsnQoUPNGMDp06dLtWrVfNNKAAAA+C8BHDVqlJQqVcp8P3LkSClSpIh0795dDh06JG+99VbWtQwAACAb1wF0fLQFRQJYp06dlO+1C3jRokVZ3SYAAAAE2jqAAAAAwcQJzKAucArA6OjoS8aZe/fu/bdtAgAAyFYhllWAGS4A+/Tp4/H6zJkzZnFo7QoeMGBAVrYNAAAAgVAAPvXUU+nunzhxomzcuDEr2gQAAJCtHLsCwIzPAr6Yli1byuzZs7PqdAAAAAj0SSCzZs0yzwUGAADIaRzLIsBMLQSd+ofkcrnkwIEDZh3AN954I6vbBwAAAH8XgG3btvUoAPWxcMWKFZPGjRvLNddcI4Hg78U8kxgIVkXq9vR3EwD4yMktr+f8MXHBWgAOGzbMNy0BAABAYBa8uXLlkoMHD16w//Dhw+Y9AACAnMbhUXCXpmP+0pOcnCx58uTJijYBAABkq5DArNP8XwCOHz/efNVK9p133pECBQqkvHfu3DlZvXp1wIwBBAAAQBYUgGPGjElJACdPnuzR3avJX/ny5c1+AACAnCaEBDB9CQkJ5muTJk3ks88+kyJFiviyXQAAAAiUMYArVqzwTUsAAAD8xAnQyRoBMwv47rvvlpdeeumC/aNHj5Z77703q9oFAACAQCkAdbLHHXfcke6zgPU9AACAnDgGMMRHW1AUgImJieku9xIaGirHjx/PqnYBAAAgUArA6tWry8cff3zB/o8++kiqVq2aVe0CAADINo7juy2jtEe1devWUrp0aTM2ce7cuRccs337dmnTpo1ERERI/vz5pW7durJv3z7fTQIZMmSI3HXXXbJnzx659dZbzb5ly5bJzJkzZdasWRk9HQAAgN+FBNAkkKSkJKlRo4Y89thjpuZKS2uwBg0aSJcuXWT48OFSqFAh+fHHHyVv3ry+KwC1ItVKdNSoUabgCw8PN41cvny5REZGZvR0AAAASDOvQreLeeaZZ8x8DJ2A63bVVVeJT7uAVatWrWTt2rWmQt27d6906NBB+vfvbwpBAACAnCbEh5s+LlfnSaTedF9mnD9/XhYuXCiVKlWS5s2bS/HixeXGG29Mt5v4cvebKdo/3alTJ9M//eqrr5ru4A0bNmT2dAAAAEEpLi7OjNVLvem+zDh48KCZkPviiy9KixYt5KuvvpL27dubruJVq1b5pgv4wIEDMnXqVHn33XdN9arJn1awWnUyAQQAAORUjg+HAMbGxkpMTIzHvrCwsEwngKpt27bSt29f833NmjVl3bp15pG8jRo1ytoEUMf+Va5cWb777jsZO3as/PHHHzJhwoRMNR4AAMAWYWFhZqJG6i2zBeAVV1whuXPnviB4q1Klim9mAX/55ZfSu3dv6d69u1SsWDFjrQUAAAhgIQE0C/hSdC1mXfJlx44dHvt37twp5cqVy/oCcM2aNabrt3bt2qbKfOSRR+T+++/PWKsBAABwSTrGb/fu3SmvExISJD4+3qy2EhUVJQMGDJD77rtPGjZsKE2aNJFFixbJ559/LitXrhRved0FfNNNN8nbb78t+/fvlyeffNIs/KwTQLQvesmSJfLPP/94fVEAAIBA4gTQQtAbN26UWrVqmU3p+EH9fujQoea1TvrQ8X66DIw+oOOdd96R2bNnm7UBvb5fl8vlkkzS+FFTwenTp8vRo0fl9ttvl/nz54u/nTrr7xYA8JUidXv6uwkAfOTkltf9du1hX+3y3bmbBd7QuUwvA6N0UohWn7/99pt8+OGHWdcqAAAA+EyGnwSSnly5ckm7du3MBgAAkNOE5JBJIAGRAAIAAMDSBBAAACAnc+wKAEkAAQAAbEMCCAAArBdCAggAAIBgRgIIAACs54hdESAFIAAAsF6IXfUfXcAAAAC2IQEEAADWCyEBBAAAQDAjAQQAANZzLFsJmgQQAADAMiSAAADAeiF2BYAkgAAAALYhAQQAANZzLEsAKQABAID1QiyrAOkCBgAAsAwJIAAAsF6IXQEgCSAAAIBtSAABAID1HBJAAAAABDMSQAAAYL0QsSsCJAEEAACwDAkgAACwnmNXAEgBCAAAEGJZAUgXMAAAgGVIAAEAgPVCLOsDJgEEAACwDAkgAACwnmNXAEgCCAAAYBsSQAAAYL0QyyJAEkAAAADLkAACAADrOXYFgBSAAAAAIWIX2+4XAADAeiSAAADAeo5lfcAkgAAAAJYhAQQAANZzxC4kgAAAAJYhAQQAANYLYQwgAAAAghkJIAAAsJ4jdqEABAAA1nMsqwDpAgYAALAMCSAAALCeY1kESAIIAABgGRJAAABgvRCxi233CwAAYD0SQAAAYD2HMYAAAADwl9WrV0vr1q2ldOnSpjCdO3fuRY/t1q2bOWbs2LEZugYFIAAAsJ7jwy2jkpKSpEaNGjJx4sRLHjdnzhzZsGGDKRQzii5gAACAANKyZUuzXcrvv/8uvXr1ksWLF0urVq0yfA0KQAAAYD3Hh2MAk5OTzZZaWFiY2TLj/Pnz8sgjj8iAAQPk2muvzdQ56AIGAADWC/HhFhcXJxERER6b7susl156SXLnzi29e/fO9DlIAAEAAHwoNjZWYmJiPPZlNv3btGmTjBs3TjZv3vyvUksKQAAAYD3Hh13A/6a7N62vv/5aDh48KFFRUSn7zp07J/369TMzgX/++WevzkMBCAAAkEPo2L+mTZt67GvevLnZ/+ijj3p9HgpAAABgPUcCR2JiouzevTvldUJCgsTHx0tkZKRJ/ooWLepxfGhoqJQsWVIqV67s9TUoAAEAAALIxo0bpUmTJimv3eMHO3XqJFOnTs2Sa1AAAgAA6zkBFAE2btxYXC6X18d7O+4vNZaBAQAAsAwJIAAAsF5IQI0C9D0KQAAAYD3HrvqPLmAAAADbkAACAADrOZZ1AZMAAgAAWIYEEAAAWM+xKwAkAQQAALANCSAAALBeCGMAAQAAEMxIAAEAgPUcuwJACkAAAADHsgKQLmAAAADLkAACAADrOUwCAQAAQDAjAQQAANYLsSsAJAEEAACwDQkgAACwnsMYQAAAAASzgCgAv/76a3n44YelXr168vvvv5t906dPlzVr1vi7aQAAwJJ1AB0fbYHI7wXg7NmzpXnz5hIeHi5btmyR5ORks//YsWMyatQofzcPAABY0gXs+Oj/ApHfC8ARI0bI5MmT5e2335bQ0NCU/fXr15fNmzf7tW0AAADByO+TQHbs2CENGza8YH9ERIQcPXrUL20CAAB2CQnMoC54E8CSJUvK7t27L9iv4/8qVKjglzYBAAAEM78XgI8//rg89dRT8s0334jjOPLHH3/IBx98IP3795fu3bv7u3kAAMACjmVjAP3eBTxo0CA5f/683HbbbXLixAnTHRwWFmYKwF69evm7eQAAAEHHcblcLgkAp0+fNl3BiYmJUrVqVSlQoECmz3XqbJY2DQEqKSlRJo4fJ8uXLZUjRw7LNVWqysBBg6Va9ev83TT4UJG6Pf3dBGSx/o81k3a31pBK5UvIyeQz8s3WvfLMuHmy65eD6R4/9/Xu0rz+tdKh71vy+crvsr298J2TW17327XX7PrbZ+duULGIBBq/J4BuefLkMYUf4K1hQ5+V3bt2ycgXR0uxYsVl4YL58mTXR+Wz+V9IiRIl/N08AF665fqrZfLHq2XTj79I7ty5ZHjP1rJgUk+pddcIOXHqtMexvR5qIoERWwA5m98LwCZNmpixfxezfPnybG0PcoZTp07JsiVfydgJb0jtOnXNvu49esmqlSvk049mSs+n+vq7iQC81LbnGx6vn3huhvy6/EWpVbWsrN28J2X/dZWulKceuVXqPzRafl4a54eWIpg5Yhe/F4A1a9b0eH3mzBmJj4+XH374QTp16uS3diGwnTt3Vs6dO2fGi6amr7dsYf1IICcrVCCv+fr3sRMp+8LzhsrUuM7S58VP5M/D//ixdQhWIYH6yI5gLQDHjBmT7v5hw4aZ8YCXo08OcT89xM2VK+yCwgDBJX/+AlKjZi15a/IbEl2hghQteoV8+cUC+W5rvJSNivJ38wBkkvYIvdz/Hlm3ZY9s27M/Zf/ofnfLhq0JsmDl935tHxAs/L4MzMXos4Hfe++9yx4XFxdnFo1Ovb38El0DNhgZN1p0DtPtTRpK3VrVZeaM6dLijlYSEhKw/7MGcBljYzvItVeXko6DpqTsa9WoujS+oZIMeHmWX9uG4Ob4cAtEfk8AL2b9+vWSN+//ugEuJTY2VmJiYi5IABH8NOl77/0ZZvkgnRGsE0EG9OsjZcqU9XfTAGTCmKfvlTtuqSZNu4yV3w/+/5OgGtetJBXKXCEHVr/scfyHr3SVtVv2SPPHx/mhtUDO5vcC8K677vJ4rYnO/v37ZePGjTJkyJDLfl67etN297IMjF3y5ctntuPHjsn6tWukT8wAfzcJQCaKvza31pBmj4+TX/447PHeK1O+kilz1nns2zTrGRn46mxZuOqHbG4pgpYjVvF7Aahdtqlp913lypXl+eefl2bNmvmtXQh8a9d8rf9ikHLR0fLrvn0y5pXRUj66grRt7/mPCgCB3+17X8s6cm/ftyQx6ZSUKFrQ7D+WeEpOJZ8xkz7Sm/jx6/6/LygWAeSAAlBncT766KNSvXp1KVIk8BZJRGBLTPxHxo99Tf48cEAiIgrLbbc3k15P9ZXQ0FB/Nw1ABjzZoaH5uuSdPh77Hx86XWZ8/o2fWgXbOJZFgH5/EoiO89u+fbtER0dn2TnpAgaCF08CAYKXP58E8s2eYz47941XefZ2BgK/T5esVq2a7N2719/NAAAAFnMc322ByO8F4IgRI6R///6yYMECM/nj+PHjHhsAAICvOSwDkz10kke/fv3kjjvuMK/btGnj8Ug47ZnW1zpOEAAAAEFQAA4fPly6desmK1as8FcTAAAA/idQo7pgKwDdc08aNWrkryYAAABYya/LwKTu8gUAAPAXx7II0K8FYKVKlS5bBB45ciTb2gMAAGADvxaAOg4w7ZNAAAAAsptjVwDo3wLw/vvvl+LFi/uzCQAAANbxWwHI+D8AABAoHLGL32cBAwAA+J0jVvFbAXj+/Hl/XRoAAMBqfh0DCAAAEAgcyyJAvz8LGAAAAP9v9erV0rp1ayldurSZMzF37tyU986cOSNPP/20VK9eXfLnz2+O6dixo/zxxx+SERSAAADAeo7juy2jkpKSpEaNGjJx4sQL3jtx4oRs3rxZhgwZYr5+9tlnsmPHDmnTpk2GrkEXMAAAQABp2bKl2dKj6ycvWbLEY9/rr78uN9xwg+zbt0+ioqK8ugYFIAAAsJ7jw3MnJyebLbWwsDCzZYVjx46ZruLChQt7/Rm6gAEAAHwoLi7OJHepN92XFU6dOmXGBD7wwANSqFAhrz9HAggAAOD47tSxsbESExPjsS8r0j+dENKhQweztvKkSZMy9FkKQAAAYD3HhxVgVnb3pi3+fvnlF1m+fHmG0j9FAQgAAJCDuIu/Xbt2yYoVK6Ro0aIZPgcFIAAAsJ4TQOtAJyYmyu7du1NeJyQkSHx8vERGRkqpUqXknnvuMUvALFiwQM6dOycHDhwwx+n7efLk8eoajisIH8p76qy/WwDAV4rU7envJgDwkZNbXvfbtb//LdFn565epkCGjl+5cqU0adLkgv2dOnWSYcOGSXR0dLqf0zSwcePGXl2DBBAAAFjPkcChRdyl8rmsyO5YBgYAAMAyJIAAAACOWIUEEAAAwDIkgAAAwHqOZREgCSAAAIBlSAABAID1HLsCQApAAAAAR+xCFzAAAIBlSAABAAAcsQoJIAAAgGVIAAEAgPUcyyJAEkAAAADLkAACAADrOXYFgCSAAAAAtiEBBAAA1nPELhSAAAAAjliFLmAAAADLkAACAADrOZZFgCSAAAAAliEBBAAA1nPsCgBJAAEAAGxDAggAAKzniF1IAAEAACxDAggAAOCIVSgAAQCA9RzLKkC6gAEAACxDAggAAKzn2BUAkgACAADYhgQQAABYzxG7kAACAABYhgQQAADAEauQAAIAAFiGBBAAAFjPsSwCpAAEAADWc+yq/+gCBgAAsA0JIAAAsJ4jdiEBBAAAsAwJIAAAsJ5jWQRIAggAAGAZEkAAAACxKwIkAQQAALAMCSAAALCeY1cASAEIAADgiF3oAgYAALAMCSAAALCeY1kESAIIAABgGRJAAABgPceyUYAkgAAAAJYhAQQAAHDEKiSAAAAAliEBBAAA1nPELiSAAADAeo7juy2jVq9eLa1bt5bSpUuL4zgyd+5cj/ddLpcMHTpUSpUqJeHh4dK0aVPZtWtXhq5BAQgAABBAkpKSpEaNGjJx4sR03x89erSMHz9eJk+eLN98843kz59fmjdvLqdOnfL6GnQBAwAA6zkB1AncsmVLs6VH07+xY8fKs88+K23btjX7pk2bJiVKlDBJ4f333+/VNUgAAQAAfCg5OVmOHz/usem+zEhISJADBw6Ybl+3iIgIufHGG2X9+vVen4cCEAAAwPHdFhcXZ4q01Jvuywwt/pQmfqnpa/d73qALGAAAwIdiY2MlJibGY19YWJj4EwUgAACwnuPDc2uxl1UFX8mSJc3XP//808wCdtPXNWvW9Po8dAEDAADkENHR0aYIXLZsWco+HVOos4Hr1avn9XlIAAEAgPWcwJkELImJibJ7926PiR/x8fESGRkpUVFR0qdPHxkxYoRUrFjRFIRDhgwxawa2a9fO62tQAAIAAOs5AbQMzMaNG6VJkyYpr93jBzt16iRTp06VgQMHmrUCn3jiCTl69Kg0aNBAFi1aJHnz5vX6Go5LF5QJMqfO+rsFAHylSN2e/m4CAB85ueV1v137SNI5n507Mn8uCTQkgAAAwHpO4ASA2YJJIAAAAJahAAQAALAMBSAAAIBlGAMIAACs5zAGEAAAAMGMBBAAAFjPCaB1ALMDBSAAALCeY1f9RxcwAACAbUgAAQCA9RyxCwkgAACAZUgAAQAAHLEKCSAAAIBlSAABAID1HMsiQBJAAAAAy5AAAgAA6zl2BYAkgAAAALYhAQQAANZzxC4UgAAAAI5YhS5gAAAAy5AAAgAA6zmWRYAkgAAAAJYhAQQAANZz7AoASQABAABs47hcLpe/GwFkVnJyssTFxUlsbKyEhYX5uzkAshC/34DvUAAiRzt+/LhERETIsWPHpFChQv5uDoAsxO834Dt0AQMAAFiGAhAAAMAyFIAAAACWoQBEjqYDw5977jkGiANBiN9vwHeYBAIAAGAZEkAAAADLUAACAABYhgIQAADAMhSAyLGmTp0qhQsX9nczAADIcSgA4XedO3cWx3Eu2Hbv3u3vpgHIIun9jqfehg0b5u8mAlbJ7e8GAKpFixYyZcoUj33FihXzW3sAZK39+/enfP/xxx/L0KFDZceOHSn7ChQokPK9Lk5x7tw5yZ2bv6IAXyEBREDQdb5KlizpsY0bN06qV68u+fPnl7Jly8p//vMfSUxMvOg5tm7dKk2aNJGCBQua54bWrl1bNm7cmPL+mjVr5JZbbpHw8HBzvt69e0tSUlI23SFgt9S/2/p8X0393K9/+ukn83v75Zdfmt9b/fNAf1+1d6Bdu3Ye5+nTp480btw45fX58+clLi5OoqOjze92jRo1ZNasWX64QyBnoQBEwAoJCZHx48fLjz/+KO+//74sX75cBg4ceNHjH3roISlTpox8++23smnTJhk0aJCEhoaa9/bs2WNSxrvvvlu+++47k0DoXzA9e/bMxjsCcCn6O/viiy/K9u3b5brrrvPqM1r8TZs2TSZPnmz+rOjbt688/PDDsmrVKp+3F8jJyNcREBYsWODRBdSyZUv59NNPU16XL19eRowYId26dZM33ngj3XPs27dPBgwYINdcc415XbFiRY+/JLRA1PTA/Z4Wl40aNZJJkyZJ3rx5fXh3ALzx/PPPy+233+718cnJyTJq1ChZunSp1KtXz+yrUKGC+cfdm2++aX6/AaSPAhABQbtutRBz025f/UNdCzftHjp+/LicPXtWTp06JSdOnJB8+fJdcI6YmBjp2rWrTJ8+XZo2bSr33nuvXHXVVSndw5r8ffDBBx7jjLT7KCEhQapUqZJNdwrgYurUqZOh43WimP55kLZoPH36tNSqVSuLWwcEFwpABAQt+K6++uqU1z///LPceeed0r17dxk5cqRERkaaf9V36dLF/OGeXgGoswgffPBBWbhwoRlLpM8Q/eijj6R9+/Zm7OCTTz5pxv2lFRUV5fP7A+DdnwNph4GkfVrpmTNnUr53jwnW3/krr7zS4zieHwxcGgUgApKO4dN07tVXXzV/CahPPvnksp+rVKmS2XQc0AMPPGBmFmsBeP3118u2bds8ikwAgU1XAvjhhx889sXHx6eM7a1ataop9HT4B929QMYwCQQBSQs1/Zf+hAkTZO/evaZbVwd5X8zJkyfNhI6VK1fKL7/8ImvXrjWTQdxdu08//bSsW7fOHKN/gezatUvmzZvHJBAggN16661mJr9O8tDfWU31UxeEOnO4f//+5h98OlFMJ3tt3rzZ/LmhrwFcHAUgApIu5fDaa6/JSy+9JNWqVTNj93Q84MXkypVLDh8+LB07djQJYIcOHcxEkuHDh5v3dUahzgrcuXOnWQpGxwfpOmSlS5fOxrsCkBHNmzeXIUOGmNn/devWlX/++cf8jqf2wgsvmGP0zwf9B5/O9tcuYV0WBsDFOa60AywAAAAQ1EgAAQAALEMBCAAAYBkKQAAAAMtQAAIAAFiGAhAAAMAyFIAAAACWoQAEAACwDAUgAACAZSgAAQSszp07S7t27VJeN27cWPr06ZPt7dBHDDqOI0ePHs32awOAL1AAAshUYaYFkW558uQxz25+/vnn5ezZsz697meffWYe/eUNijYAuLjcl3gPAC5Kn7k6ZcoUSU5Oli+++EJ69OghoaGhEhsb63Hc6dOnTZGYFSIjI7PkPABgOxJAAJkSFhYmJUuWlHLlykn37t2ladOmMn/+/JRu25EjR0rp0qWlcuXK5vhff/1VOnToIIULFzaFXNu2beXnn39OOd+5c+ckJibGvF+0aFEZOHCgpH1UedouYC0+n376aSlbtqxpjyaR7777rjlvkyZNzDFFihQxSaC2S50/f17i4uIkOjpawsPDpUaNGjJr1iyP62hBW6lSJfO+nid1OwEgGFAAAsgSWixp2qeWLVsmO3bskCVLlsiCBQvkzJkz0rx5cylYsKB8/fXXsnbtWilQoIBJEd2fefXVV2Xq1Kny3nvvyZo1a+TIkSMyZ86cS16zY8eO8uGHH8r48eNl+/bt8uabb5rzakE4e/Zsc4y2Y//+/TJu3DjzWou/adOmyeTJk+XHH3+Uvn37ysMPPyyrVq1KKVTvuusuad26tcTHx0vXrl1l0KBBPv7pAUD2ogsYwL+iKZ0WfIsXL5ZevXrJoUOHJH/+/PLOO++kdP3OmDHDJG+6T9M4pd3HmvbpWL1mzZrJ2LFjTfexFl9KCzQ958Xs3LlTPvnkE1NkavqoKlSocEF3cfHixc113InhqFGjZOnSpVKvXr2Uz2jBqcVjo0aNZNKkSXLVVVeZglRpgvn999/LSy+95KOfIABkPwpAAJmiyZ6mbZruaXH34IMPyrBhw8xYwOrVq3uM+9u6davs3r3bJICpnTp1Svbs2SPHjh0zKd2NN96Y8l7u3LmlTp06F3QDu2k6lytXLlO0eUvbcOLECbn99ts99msKWatWLfO9Jomp26HcxSIABAsKQACZomPjNC3TQk/H+mnB5qYJYGqJiYlSu3Zt+eCDDy44T7FixTLd5ZxR2g61cOFCufLKKz3e0zGEAGALCkAAmaJFnk668Mb1118vH3/8semOLVSoULrHlCpVSr755htp2LChea1LymzatMl8Nj2aMmryqGP33F3AqbkTSJ1c4la1alVT6O3bt++iyWGVKlXMZJbUNmzY4NV9AkBOwSQQAD730EMPyRVXXGFm/uokkISEBDP2r3fv3vLbb7+ZY5566il58cUXZe7cufLTTz/Jf/7zn0uu4Ve+fHnp1KmTPPbYY+Yz7nPquECls5N1vKF2Veu4RE3/tAu6f//+ZuLH+++/b7qfN2/eLBMmTDCvVbdu3WTXrl0yYMAAM4Fk5syZZnIKAAQTCkAAPpcvXz5ZvXq1REVFmUkemrJ16dLFjAF0J4L9+vWTRx55xBR1OuZOi7X27dtf8rzaBX3PPfeYYvGaa66Rxx9/XJKSksx72sU7fPhwM4O3RIkS0rNnT7NfF5IeMmSImQ2s7dCZyNolrMvCKG2jziDWolKXiNHJKDpxBACCieO62AhrAAAABCUSQAAAAMtQAAIAAFiGAhAAAMAyFIAAAACWoQAEAACwDAUgAACAZSgAAQAALEMBCAAAYBkKQAAAAMtQAAIAAFiGAhAAAEDs8n+4XBBUJRQABgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the features and target variable\n",
    "features = weather_feature_names + ['day_of_year']\n",
    "target = 'PowderyMildew'\n",
    "\n",
    "X = observations_df[features]\n",
    "y = observations_df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=300, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)\n",
    "\n",
    "# Create and display confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix with labels\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                             display_labels=[False, True])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity has improved to 72%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Select top 20 features\n",
    "top_20_features = feature_importance_df.head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=top_20_features)\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature and seasonality are very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  ARDRegression\n",
      "Testing for model:  AdaBoostClassifier\n",
      "Testing for model:  AdaBoostRegressor\n",
      "Testing for model:  AdditiveChi2Sampler\n",
      "Testing for model:  AffinityPropagation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_affinity_propagation.py:140: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  AgglomerativeClustering\n",
      "Testing for model:  BaggingClassifier\n",
      "Testing for model:  BaggingRegressor\n",
      "Testing for model:  BayesianGaussianMixture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  BayesianRidge\n",
      "Testing for model:  BernoulliNB\n",
      "Testing for model:  BernoulliRBM\n",
      "Testing for model:  Binarizer\n",
      "Testing for model:  Birch\n",
      "Testing for model:  BisectingKMeans\n",
      "Testing for model:  CCA\n",
      "Testing for model:  CalibratedClassifierCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  CategoricalNB\n",
      "Testing for model:  ClassifierChain\n",
      "Testing for model:  ColumnTransformer\n",
      "Testing for model:  ComplementNB\n",
      "Testing for model:  CountVectorizer\n",
      "Testing for model:  DBSCAN\n",
      "Testing for model:  DecisionTreeClassifier\n",
      "Testing for model:  DecisionTreeRegressor\n",
      "Testing for model:  DictVectorizer\n",
      "Skipping DictionaryLearning\n",
      "Testing for model:  DummyClassifier\n",
      "Testing for model:  DummyRegressor\n",
      "Testing for model:  ElasticNet\n",
      "Testing for model:  ElasticNetCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01353539577785412, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011517970858552218, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02526505998812212, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.049555934920483935, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05693609545946998, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03426840508516804, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.024971524944064072, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04923925929233164, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05677921867700064, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07102015609925161, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07863258338750967, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10188322154760243, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08004642239568582, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07522849918944274, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09295774907618437, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14789866494368908, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.20029284428772698, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15627611481101766, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2952307415086395, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.37642693359765644, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3917741760818494, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.005394630584760307, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007889476103699167, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02507781673439169, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.059080023402156456, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09250466818087588, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15487456512483888, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07450779975314603, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09902407169532168, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1961175448067145, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.312487777527668, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5922606624937714, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.482581006414712, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16640309207408777, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1236079532149077, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15392962330692228, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1620120065278705, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.20427226613469784, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.29216082825860923, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.44744686232180086, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.015190030667838528, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019076438919661598, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.024196339846454862, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020847216146094638, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014237074093152557, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03551593764517946, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.032019370067974506, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03455285772757222, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05351756116746742, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12114599036156193, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08369770582160285, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07765560417373862, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1060648559161308, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17058532399937576, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17197367057088542, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16489299568450022, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2422182782254616, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.28695898326092717, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.28520873035592587, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.34948763919376447, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.40508752311690444, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.43532959885042644, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.46144448036578467, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.528697807615103, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008122351342031209, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006175509975051341, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009615441350398157, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02489310400450151, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03316492409698668, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06748968343081074, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.056660119063842274, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03433047648585941, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05014653030018934, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.061253479564371105, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0629010752016228, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03244300529700439, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12158436233661618, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11758657226918956, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11267020214429735, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08335847486635828, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06491054437718802, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09563092831894338, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21349299097791175, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2297700306251329, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.32133504726182593, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3579849910049653, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3378324405838242, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.41650088644306393, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.45808285075340294, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008179707854083063, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007758533119947231, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009020885893860964, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010097960312116072, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014133034303739578, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02355577726075353, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03318229698336239, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03124981552318218, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.017380382314570397, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.032310027070188596, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.031235606189337517, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.037674773963164654, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023451763258378833, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018808234323323347, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04024446583446917, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014008355335651146, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04438728214587684, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.039675502469741275, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06569756606941368, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08178438618804407, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11373400395581612, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16630672472144425, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2223632990765907, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2962954859976854, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3739234842069976, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4319398202723619, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5578800716979764, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.656885573687287, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_robust_covariance.py:749: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_robust_covariance.py:185: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-1288.009166189317511 > -1331.703831809496251). You may want to try with a higher value of support_fraction (current value: 0.738).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  EllipticEnvelope\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  EmpiricalCovariance\n",
      "Testing for model:  ExtraTreeClassifier\n",
      "Testing for model:  ExtraTreeRegressor\n",
      "Testing for model:  ExtraTreesClassifier\n",
      "Testing for model:  ExtraTreesRegressor\n",
      "Testing for model:  FactorAnalysis\n",
      "Testing for model:  FastICA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  FeatureAgglomeration\n",
      "Testing for model:  FeatureHasher\n",
      "Testing for model:  FeatureUnion\n",
      "Testing for model:  FixedThresholdClassifier\n",
      "Testing for model:  FrozenEstimator\n",
      "Testing for model:  FunctionTransformer\n",
      "Testing for model:  GammaRegressor\n",
      "Testing for model:  GaussianMixture\n",
      "Testing for model:  GaussianNB\n",
      "Testing for model:  GaussianProcessClassifier\n",
      "Testing for model:  GaussianProcessRegressor\n",
      "Testing for model:  GaussianRandomProjection\n",
      "Testing for model:  GenericUnivariateSelect\n",
      "Testing for model:  GradientBoostingClassifier\n",
      "Testing for model:  GradientBoostingRegressor\n",
      "Testing for model:  GraphicalLasso\n",
      "Testing for model:  GraphicalLassoCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1543.6057621944965, tolerance: 3.322917703722296\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17268.464160304295, tolerance: 4.077165036358861\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.1392281242369067\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.133509227023094\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.760385852935057\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.080537640139911\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.047521491505197\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.9715630810388896\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.616883457684715\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.929361501810992\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.017914105363841\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.7262327933974095\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.0714206198333525\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.5410068250735196\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.8167839610251146\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 19.28535355730527\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 28.086268966357796\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 6.702642894742862\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 20.30827126802729\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 17.605509814014397\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 25.912610661051794\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.6817066667586946\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 18.781591011327478\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 14.517908358193553\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 20.20092139196864\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.43047052520490164\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 16.76758318089859\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 11.199225859332316\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 16.86983612550483\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.15074714526213193\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 13.92860461874602\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.06629083145488235\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.04620867039723964\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.09487757001019786\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.06694429899277415\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.07893371369716919\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.0128406009796045\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.15281502720028148\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.0915140796258309\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.0803214973430165\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.0086321024394007\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.2327165084082252\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.08676760305386645\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.07001545937099533\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.0011490772485403685\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.2523016710817852\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.07319182443995105\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.25230167108178514\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.928834254440747\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 4.210099785921419\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.195930168871151\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.9798817251215493\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.529723651911731\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.8669727822657762\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.473153555937988\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.684631502674795\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.1953694620225717\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.4717075202275325\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 1.8265850860727064\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.4119402175471043\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.696028695672345\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.80142222597082\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 1.438417541039894\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.9787581693034775\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 1.4384175410398943\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.287177028026478\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 4.094084283403134\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.8394912743372145\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.190664922990134\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.026753483909683\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.7155377019292617\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.2053981787377546\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.1266015162830936\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.8364960452546395\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.585803430932259\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 1.882006794228883\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.9264405345852396\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.5183903374659042\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.952750426234669\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 1.5003452532825863\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 2.692720605257752\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 1.500345253282586\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.9711081402019749\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.7947115387486129\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 1.0458786114135477\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.9788562905407415\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.8581374593275378\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.5954218044391383\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.9459922261916321\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.9113646954712875\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.7664410812927248\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.4328793356517224\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.8726132379144816\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.8165136995893744\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.6602187516596265\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.2709761755181809\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.8015116601815344\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 0.7203131671815264\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 27.328551179472107\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.322917703722296\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_graph_lasso.py:140: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: nan, tolerance: 3.640472642826059\n",
      "  coefs, _, _, _ = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/_methods.py:173: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  GridSearchCV\n",
      "Testing for model:  HDBSCAN\n",
      "Testing for model:  HashingVectorizer\n",
      "Testing for model:  HistGradientBoostingClassifier\n",
      "Testing for model:  HistGradientBoostingRegressor\n",
      "Testing for model:  HuberRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  IncrementalPCA\n",
      "Testing for model:  IsolationForest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 22 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 26 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 30 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 34 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 38 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  Isomap\n",
      "Testing for model:  IsotonicRegression\n",
      "Testing for model:  KBinsDiscretizer\n",
      "Testing for model:  KMeans\n",
      "Testing for model:  KNNImputer\n",
      "Testing for model:  KNeighborsClassifier\n",
      "Testing for model:  KNeighborsRegressor\n",
      "Testing for model:  KNeighborsTransformer\n",
      "Testing for model:  KernelCenterer\n",
      "Testing for model:  KernelDensity\n",
      "Testing for model:  KernelPCA\n",
      "Testing for model:  KernelRidge\n",
      "Testing for model:  LabelBinarizer\n",
      "Testing for model:  LabelEncoder\n",
      "Testing for model:  LabelPropagation\n",
      "Testing for model:  LabelSpreading\n",
      "Testing for model:  Lars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/semi_supervised/_label_propagation.py:231: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.084e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.952e-01, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.550e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.765e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=5.708e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=4.365e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=4.092e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=3.800e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=4.892e+00, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=5.712e+01, with an active set of 98 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=4.521e+05, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=4.382e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=4.191e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=3.392e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=3.249e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=2.986e+05, with an active set of 104 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=2.661e+05, with an active set of 110 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=2.642e+05, with an active set of 110 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=2.446e+05, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=1.026e+06, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=5.542e+05, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=1.363e+05, with an active set of 116 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=2.386e+05, with an active set of 118 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=1.938e+05, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=9.643e+04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.921e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.120e-01, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.054e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.012e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=1.096e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=9.632e-02, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=9.451e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=9.317e-02, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=7.947e-02, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=7.571e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=7.601e-02, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.468e-02, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=7.119e-02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=7.098e-02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=6.267e-02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=1.800e+02, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.578e+02, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  LarsCV\n",
      "Testing for model:  Lasso\n",
      "Testing for model:  LassoCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=1.316e+02, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=1.209e+02, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 160 iterations, i.e. alpha=1.034e+02, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=1.974e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.531e+02, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 175 iterations, i.e. alpha=2.826e+02, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=1.084e+05, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=4.116e+04, with an active set of 119 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=1.689e+03, with an active set of 119 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.561e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.305e-01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.099e-01, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.032e-01, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.495e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.312e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.006e-01, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.164e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=3.251e-01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=3.155e-01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=3.072e-01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=4.127e-01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=9.068e+00, with an active set of 74 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.241e+02, with an active set of 99 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 171 iterations, i.e. alpha=2.078e+02, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=2.073e+02, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=1.944e+02, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=1.705e+02, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=1.615e+02, with an active set of 110 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 189 iterations, i.e. alpha=1.596e+02, with an active set of 110 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=1.331e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=1.892e+02, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=3.801e+02, with an active set of 113 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=5.333e+02, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=4.987e+02, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=3.362e+02, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=2.701e+02, with an active set of 114 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=1.313e+02, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=1.094e+02, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=4.861e+01, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=2.509e+01, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=1.869e+01, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=1.555e+01, with an active set of 115 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.447e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.389e-01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.059e-01, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.451e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.891e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.832e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.562e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.403e-01, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.187e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=3.081e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.823e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=2.605e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=2.320e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=1.824e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.810e-01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.810e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.806e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.786e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=6.414e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=6.411e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=6.396e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=6.344e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=6.287e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=6.271e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=6.270e+00, with an active set of 100 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=6.592e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=6.021e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=5.814e+00, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=5.074e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=4.704e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=4.118e+01, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=4.161e+01, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 195 iterations, i.e. alpha=2.375e+02, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=8.305e+04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.849e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.776e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.716e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.609e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=2.222e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.953e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.410e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.255e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.240e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=2.283e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.945e-01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=1.444e-01, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.349e-01, with an active set of 85 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=2.318e+08, with an active set of 120 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.869e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.414e-01, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.196e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.048e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=1.722e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.533e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.490e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.331e-01, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.291e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.199e-01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.090e-01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=9.025e-02, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 82 iterations, i.e. alpha=8.656e-02, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=8.460e-02, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 151 iterations, i.e. alpha=4.017e+02, with an active set of 103 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 152 iterations, i.e. alpha=3.989e+02, with an active set of 104 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 158 iterations, i.e. alpha=1.053e+03, with an active set of 105 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=1.057e+03, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=8.721e+02, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.702e+02, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=5.361e+02, with an active set of 106 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.768e+02, with an active set of 108 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=4.376e+02, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 166 iterations, i.e. alpha=4.079e+02, with an active set of 109 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 168 iterations, i.e. alpha=3.544e+02, with an active set of 110 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.648e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.352e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=2.216e+02, with an active set of 111 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=2.005e+02, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.420e+02, with an active set of 112 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 176 iterations, i.e. alpha=5.583e+01, with an active set of 115 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=4.573e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=3.449e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=2.118e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.274e+01, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 177 iterations, i.e. alpha=1.409e+00, with an active set of 116 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.084e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.952e-01, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.550e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.765e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007885569174508333, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011581348283364434, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05711856978542329, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.025503427908965648, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06211448105296924, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.038055014503118656, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04143945656946002, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06957503979649005, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06640514825170385, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08648323332926466, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08309408287921727, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09682817500800667, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07411998840077771, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09088520118275412, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09590639536679291, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15051809557017748, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.21536989950513075, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.41493162755264734, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6112805546810307, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6000024730601439, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5326494055891864, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4825801024614904, tolerance: 0.0050921568627450954\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006063833100586891, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0106947866831959, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.042446477160346774, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0680747787084961, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09463990326733551, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10900605860333457, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06973675022511827, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14809278348525012, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.25288275342440514, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.48455724028017144, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7437578762517347, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5085297617040894, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2552789684158121, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2762270214814144, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.34058150241382634, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3318715264655303, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.36185313124456897, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4941505947827274, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6697124486664059, tolerance: 0.005124878048780488\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009425914284861392, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01924956862309557, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.017377486842249823, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01653339187161862, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018423352863244702, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0357815311041314, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04366957737585864, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.040794805339338325, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.058597044699141065, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13635514624079903, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07799805638896729, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04537234370803134, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05659374337911416, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09604887892988856, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12838319436090728, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18880759844253348, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3153140669493162, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4119161243641045, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.513346082427983, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5668622065468654, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5771495790900971, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6809205530792006, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5917521101265031, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6426547973130212, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006806504358912946, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.033572275101878546, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04161921150882364, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08799969699906285, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0649182408764375, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03976788280350263, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09023250740798971, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0727792625058079, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07235183869594053, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11083585787906713, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2144094248826569, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1881439486178067, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1256757471838732, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10344641849536274, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13637594589528845, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10917211643151248, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2172577762053578, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4319175106913882, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5037301045802991, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5207647580716923, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5839989269680892, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6565218757178215, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.767728820410948, tolerance: 0.005119024390243903\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007095980910904132, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011953093164144946, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01287052329110594, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014804735042723394, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.035365781428268406, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04076279239663094, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.017571177487862855, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018491739523391004, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.026102555652144588, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029698919894833864, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03335205922886786, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.022179957463560385, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03128582800803059, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.031694315177848154, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01608124087186269, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03596299416890503, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029926860661696253, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06197247631904901, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11051798205389574, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2117745165749625, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.17248879475823742, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.271975230522294, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.42452048876672066, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5688562430127568, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6172516279727738, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6137064076142451, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5349199809722833, tolerance: 0.005123902439024392\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.961e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.438e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.369e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:753: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.112e-01, previous alpha=1.098e-01, with an active set of 12 regressors.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=6.561e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=6.305e-01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=6.099e-01, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.032e-01, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.495e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.312e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:753: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 21 iterations, alpha=3.021e-01, previous alpha=2.904e-01, with an active set of 16 regressors.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=4.447e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=4.389e-01, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=4.059e-01, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=3.451e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:753: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 9 iterations, alpha=3.179e-01, previous alpha=2.973e-01, with an active set of 8 regressors.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.180e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.205e-02, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=7.976e-02, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=6.645e-02, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.970e-02, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.144e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.748e-02, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.333e-02, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:753: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 33 iterations, alpha=3.520e-02, previous alpha=3.322e-02, with an active set of 26 regressors.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=9.539e-02, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:753: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=6.504e-02, previous alpha=6.224e-02, with an active set of 17 regressors.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.084e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.952e-01, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.550e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.765e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:753: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=3.505e-01, previous alpha=3.287e-01, with an active set of 10 regressors.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=5.084e-01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.952e-01, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.550e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.765e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:753: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=3.505e-01, previous alpha=3.287e-01, with an active set of 10 regressors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  LassoLars\n",
      "Testing for model:  LassoLarsCV\n",
      "Testing for model:  LassoLarsIC\n",
      "Testing for model:  LatentDirichletAllocation\n",
      "Testing for model:  LedoitWolf\n",
      "Testing for model:  LinearDiscriminantAnalysis\n",
      "Testing for model:  LinearRegression\n",
      "Testing for model:  LinearSVC\n",
      "Testing for model:  LinearSVR\n",
      "Testing for model:  LocalOutlierFactor\n",
      "Testing for model:  LocallyLinearEmbedding\n",
      "Testing for model:  LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  LogisticRegressionCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  MDS\n",
      "Testing for model:  MLPClassifier\n",
      "Testing for model:  MLPRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  MaxAbsScaler\n",
      "Testing for model:  MeanShift\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_robust_covariance.py:749: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/covariance/_robust_covariance.py:185: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-1297.633449114059658 > -1345.738313751969372). You may want to try with a higher value of support_fraction (current value: 0.738).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  MinCovDet\n",
      "Testing for model:  MinMaxScaler\n",
      "Testing for model:  MiniBatchDictionaryLearning\n",
      "Testing for model:  MiniBatchKMeans\n",
      "Testing for model:  MiniBatchNMF\n",
      "Testing for model:  MiniBatchSparsePCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  MissingIndicator\n",
      "Testing for model:  MultiLabelBinarizer\n",
      "Testing for model:  MultiOutputClassifier\n",
      "Testing for model:  MultiOutputRegressor\n",
      "Testing for model:  MultiTaskElasticNet\n",
      "Testing for model:  MultiTaskElasticNetCV\n",
      "Testing for model:  MultiTaskLasso\n",
      "Testing for model:  MultiTaskLassoCV\n",
      "Testing for model:  MultinomialNB\n",
      "Testing for model:  NMF\n",
      "Testing for model:  NearestCentroid\n",
      "Testing for model:  NearestNeighbors\n",
      "Testing for model:  NeighborhoodComponentsAnalysis\n",
      "Testing for model:  Normalizer\n",
      "Testing for model:  NuSVC\n",
      "Testing for model:  NuSVR\n",
      "Testing for model:  Nystroem\n",
      "Testing for model:  OAS\n",
      "Testing for model:  OPTICS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_optics.py:1086: RuntimeWarning: divide by zero encountered in divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  OneClassSVM\n",
      "Testing for model:  OneHotEncoder\n",
      "Testing for model:  OneVsOneClassifier\n",
      "Testing for model:  OneVsRestClassifier\n",
      "Testing for model:  OrdinalEncoder\n",
      "Testing for model:  OrthogonalMatchingPursuit\n",
      "Testing for model:  OrthogonalMatchingPursuitCV\n",
      "Testing for model:  OutputCodeClassifier\n",
      "Testing for model:  PCA\n",
      "Testing for model:  PLSCanonical\n",
      "Testing for model:  PLSRegression\n",
      "Testing for model:  PLSSVD\n",
      "Testing for model:  PassiveAggressiveClassifier\n",
      "Testing for model:  PassiveAggressiveRegressor\n",
      "Testing for model:  PatchExtractor\n",
      "Testing for model:  Perceptron\n",
      "Testing for model:  Pipeline\n",
      "Testing for model:  PoissonRegressor\n",
      "Testing for model:  PolynomialCountSketch\n",
      "Testing for model:  PolynomialFeatures\n",
      "Testing for model:  PowerTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/_methods.py:187: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  QuadraticDiscriminantAnalysis\n",
      "Testing for model:  QuantileRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  QuantileTransformer\n",
      "Testing for model:  RANSACRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:2829: UserWarning: n_quantiles (1000) is greater than the total number of samples (256). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  RBFSampler\n",
      "Testing for model:  RFE\n",
      "Testing for model:  RFECV\n",
      "Testing for model:  RadiusNeighborsClassifier\n",
      "Testing for model:  RadiusNeighborsRegressor\n",
      "Testing for model:  RadiusNeighborsTransformer\n",
      "Testing for model:  RandomForestClassifier\n",
      "Testing for model:  RandomForestRegressor\n",
      "Testing for model:  RandomTreesEmbedding\n",
      "Testing for model:  RandomizedSearchCV\n",
      "Testing for model:  RegressorChain\n",
      "Testing for model:  Ridge\n",
      "Testing for model:  RidgeCV\n",
      "Testing for model:  RidgeClassifier\n",
      "Testing for model:  RidgeClassifierCV\n",
      "Testing for model:  RobustScaler\n",
      "Testing for model:  SGDClassifier\n",
      "Testing for model:  SGDOneClassSVM\n",
      "Testing for model:  SGDRegressor\n",
      "Testing for model:  SVC\n",
      "Testing for model:  SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  SelectFdr\n",
      "Testing for model:  SelectFpr\n",
      "Testing for model:  SelectFromModel\n",
      "Testing for model:  SelectFwe\n",
      "Testing for model:  SelectKBest\n",
      "Testing for model:  SelectPercentile\n",
      "Testing for model:  SelfTrainingClassifier\n",
      "Testing for model:  SequentialFeatureSelector\n",
      "Testing for model:  ShrunkCovariance\n",
      "Testing for model:  SimpleImputer\n",
      "Testing for model:  SkewedChi2Sampler\n",
      "Testing for model:  SparseCoder\n",
      "Testing for model:  SparsePCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 1 iterations, i.e. alpha=2.215e-01, with an active set of 1 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:723: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=1.028e-01, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_least_angle.py:753: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=4.825e-02, previous alpha=4.742e-02, with an active set of 7 regressors.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:329: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:425: RuntimeWarning: invalid value encountered in add\n",
      "  distances += XX\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:700: RuntimeWarning: overflow encountered in square\n",
      "  lloyd_iter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  SparseRandomProjection\n",
      "Testing for model:  SpectralBiclustering\n",
      "Testing for model:  SpectralClustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for model:  SpectralCoclustering\n",
      "Testing for model:  SpectralEmbedding\n",
      "Testing for model:  SplineTransformer\n",
      "Testing for model:  StackingClassifier\n",
      "Testing for model:  StackingRegressor\n",
      "Testing for model:  StandardScaler\n",
      "Testing for model:  TSNE\n",
      "Testing for model:  TargetEncoder\n",
      "Testing for model:  TfidfTransformer\n",
      "Testing for model:  TfidfVectorizer\n",
      "Testing for model:  TheilSenRegressor\n",
      "Testing for model:  TransformedTargetRegressor\n",
      "Testing for model:  TruncatedSVD\n",
      "Testing for model:  TunedThresholdClassifierCV\n",
      "Testing for model:  TweedieRegressor\n",
      "Testing for model:  VarianceThreshold\n",
      "Testing for model:  VotingClassifier\n",
      "Testing for model:  VotingRegressor\n",
      "                          Model  Accuracy  ...  CV Mean Score  CV Std Dev\n",
      "1            AdaBoostClassifier  0.723077  ...       0.654135    0.078952\n",
      "34         ExtraTreesClassifier  0.723077  ...       0.603894    0.127681\n",
      "6             BaggingClassifier  0.692308  ...       0.616538    0.110605\n",
      "157      RandomForestClassifier  0.676923  ...       0.613413    0.103706\n",
      "68         KNeighborsClassifier  0.676923  ...       0.660337    0.101258\n",
      "..                          ...       ...  ...            ...         ...\n",
      "201  TunedThresholdClassifierCV       NaN  ...            NaN         NaN\n",
      "202            TweedieRegressor       NaN  ...            NaN         NaN\n",
      "203           VarianceThreshold       NaN  ...            NaN         NaN\n",
      "204            VotingClassifier       NaN  ...            NaN         NaN\n",
      "205             VotingRegressor       NaN  ...            NaN         NaN\n",
      "\n",
      "[206 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_glm/glm.py:285: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import all_estimators\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "# Define the features and target variable\n",
    "features = weather_feature_names + ['day_of_year']\n",
    "target = 'PowderyMildew'\n",
    "\n",
    "X = observations_df[features]\n",
    "y = observations_df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "estimators = all_estimators()\n",
    "\n",
    "results = []\n",
    "for name, model in estimators:\n",
    "    try:\n",
    "        if name == 'DictionaryLearning':\n",
    "            print(\"Skipping DictionaryLearning\") # takes too long\n",
    "            continue\n",
    "\n",
    "        # Initialize the model\n",
    "        print(\"Testing for model: \", name)\n",
    "        model = model()\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # Perform cross-validation\n",
    "        cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-score': f1,\n",
    "            'CV Mean Score': cv_scores.mean(),\n",
    "            'CV Std Dev': cv_scores.std()\n",
    "        })\n",
    "    except Exception:\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': None,\n",
    "            'Precision': None,\n",
    "            'Recall': None,\n",
    "            'F1-score': None,\n",
    "            'CV Mean Score': None,\n",
    "            'CV Std Dev': None\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "print(df_results.sort_values('Accuracy', ascending=False))\n",
    "df_results.to_csv('model_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Model  Accuracy  ...  CV Mean Score  CV Std Dev\n",
      "1                AdaBoostClassifier  0.723077  ...       0.654135    0.078952\n",
      "157          RandomForestClassifier  0.692308  ...       0.597644    0.134352\n",
      "68             KNeighborsClassifier  0.676923  ...       0.660337    0.101258\n",
      "58   HistGradientBoostingClassifier  0.676923  ...       0.672788    0.068193\n",
      "34             ExtraTreesClassifier  0.676923  ...       0.625769    0.120624\n",
      "..                              ...       ...  ...            ...         ...\n",
      "201      TunedThresholdClassifierCV       NaN  ...            NaN         NaN\n",
      "202                TweedieRegressor       NaN  ...            NaN         NaN\n",
      "203               VarianceThreshold       NaN  ...            NaN         NaN\n",
      "204                VotingClassifier       NaN  ...            NaN         NaN\n",
      "205                 VotingRegressor       NaN  ...            NaN         NaN\n",
      "\n",
      "[206 rows x 7 columns]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.11.10"
=======
   "version": "3.12.6"
>>>>>>> 4e687d2c634c322085eee218f4bf4ed521d78180
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
