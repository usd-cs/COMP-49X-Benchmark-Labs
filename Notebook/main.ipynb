{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Init Variables\n",
    "GET_WEATHER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read observations file that already has the PowderyMildew feature\n",
    "observations_df = pd.read_csv('observations.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "observations_df = observations_df.dropna()\n",
    "\n",
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse date string and extract components\n",
    "def extract_date_components(date_string):\n",
    "    import datetime\n",
    "    # Parse ISO format date string\n",
    "    dt = datetime.datetime.fromisoformat(date_string.replace('Z', '+00:00'))\n",
    "    return dt.year, dt.month, dt.day\n",
    "\n",
    "# Extract relevant data for true observations\n",
    "lons = []\n",
    "lats = []\n",
    "years = []\n",
    "months = []\n",
    "days = []\n",
    "\n",
    "for _, row in observations_df.iterrows():\n",
    "    # Parse the coordinates string into a list of floats\n",
    "    coords = eval(row['coordinates'])\n",
    "    lons.append(coords[0])\n",
    "    lats.append(coords[1])\n",
    "    \n",
    "    # Extract the date components from the date_string\n",
    "    year, month, day = extract_date_components(row['date_string'])\n",
    "    years.append(year)\n",
    "    months.append(month)\n",
    "    days.append(day)\n",
    "    \n",
    "# Apply parsed data to the observations_df\n",
    "observations_df['longitude'] = lons\n",
    "observations_df['latitude'] = lats\n",
    "observations_df['year'] = years\n",
    "observations_df['month'] = months\n",
    "observations_df['day'] = days\n",
    "\n",
    "observations_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NASA weather data at given coordinates 7 days before and after the given date\n",
    "# \n",
    "# Parameters:\n",
    "#   lon (float): Longitude coordinate\n",
    "#   lat (float): Latitude coordinate\n",
    "#   day (int): Day of the month\n",
    "#   month (int): Month of the year\n",
    "#   year (int): Year\n",
    "#   param_list (list): List of weather parameters to retrieve\n",
    "#\n",
    "# Returns:\n",
    "#   dict: Dictionary containing the requested weather parameters with their values,\n",
    "#\n",
    "\n",
    "def get_general_weather(lon, lat, day, month, year, param_list):\n",
    "    url = \"https://power.larc.nasa.gov/api/temporal/hourly/point\"\n",
    "    \n",
    "    month_str = str(month).zfill(2)  # make sure is 2 length\n",
    "    day_str = str(day).zfill(2)      # same as above\n",
    "    start_date = f\"{year}-{month_str}-{day_str}\"\n",
    "\n",
    "    start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\") \n",
    "    end_date = start_date + datetime.timedelta(days=7)\n",
    "    start_date -= datetime.timedelta(days=7)\n",
    "\n",
    "    start_date = start_date.strftime(\"%Y%m%d\")\n",
    "    end_date = end_date.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    parameters = {\n",
    "        \"parameters\": \",\".join(param_list),\n",
    "        \"community\": \"AG\",\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"format\": \"JSON\"\n",
    "    }\n",
    "    curr_data = {}\n",
    "\n",
    "    response = requests.get(url, params=parameters)\n",
    "    data = response.json()\n",
    "    try:\n",
    "        for param in param_list:\n",
    "            curr_data[param] = data['properties']['parameter'][param]\n",
    "    except:\n",
    "        print(f\"Error getting data for {year}-{month_str}-{day_str} at {lat},{lon}\")\n",
    "        return None\n",
    "    \n",
    "    return curr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GET_WEATHER is True, fetch weather data for each observation, save to weather_data.csv\n",
    "\n",
    "if GET_WEATHER:\n",
    "    \"\"\"\n",
    "    T2M\tTemperature at 2 Meters\n",
    "    RH2M\tRelative Humidity at 2 Meters\n",
    "    WS2M\tWind Speed at 2 Meters\n",
    "    T2MDEW\tDew/Frost Point at 2 Meters\n",
    "    T2MWET\tWet Bulb Temperature at 2 Meters\n",
    "    QV2M\tSpecific Humidity at 2 Meters\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    dataframe = pd.DataFrame(columns=['Datetime','id', 'Temperature', 'Humidity', 'Wind Speed', 'Dew/Frost Point', 'Wet Bulb Temperature', 'Specific Humidity'])\n",
    "\n",
    "    for i, row in observations_df.iterrows():\n",
    "        weather_data = get_general_weather(row['longitude'], row['latitude'], row['day'], row['month'], row['year'], ['T2M', 'RH2M', 'WS2M', 'T2MDEW', 'T2MWET', 'QV2M'])\n",
    "        if weather_data is None:\n",
    "            for j in range(3):\n",
    "                weather_data = get_general_weather(row['longitude'], row['latitude'], row['day'], row['month'], row['year'], ['T2M', 'RH2M', 'WS2M', 'T2MDEW', 'T2MWET', 'QV2M'])\n",
    "                if weather_data is not None:\n",
    "                    break\n",
    "        if weather_data is None:    \n",
    "            continue\n",
    "        dates = list(weather_data['T2M'].keys())\n",
    "        id_vals = [row['id']] * len(dates)\n",
    "        temp_values = list(weather_data['T2M'].values())\n",
    "        humidity_values = list(weather_data['RH2M'].values())\n",
    "        wind_speed_values = list(weather_data['WS2M'].values())\n",
    "        dew_frost_values = list(weather_data['T2MDEW'].values())\n",
    "        wet_bulb_values = list(weather_data['T2MWET'].values())\n",
    "        specific_humidity_values = list(weather_data['QV2M'].values())\n",
    "        \n",
    "        curr_df = pd.DataFrame({\n",
    "            'Datetime': dates,\n",
    "            'id': id_vals,\n",
    "            'Temperature': temp_values,\n",
    "            'Humidity': humidity_values,\n",
    "            'Wind Speed': wind_speed_values,\n",
    "            'Dew/Frost Point': dew_frost_values,\n",
    "            'Wet Bulb Temperature': wet_bulb_values,\n",
    "            'Specific Humidity': specific_humidity_values\n",
    "        })\n",
    "        \n",
    "        dataframe = pd.concat([dataframe, curr_df], ignore_index=True)\n",
    "        # Print progress every 10 rows\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processed {i}\")\n",
    "        \n",
    "    dataframe.to_csv('weather_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weather data if not already loaded\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the weather data\n",
    "weather_df = pd.read_csv('weather_data.csv')\n",
    "\n",
    "# convert datetime to same format as observations_df\n",
    "weather_df['Datetime'] = pd.to_datetime(weather_df['Datetime'], format='%Y%m%d%H')\n",
    "weather_df['Date'] = weather_df['Datetime'].dt.date\n",
    "\n",
    "# Use same format as weather_df\n",
    "observations_df['Date'] = pd.to_datetime(observations_df[['year', 'month', 'day']])\n",
    "\n",
    "# Group by id and Date to find all unique days per ID\n",
    "day_indices = weather_df.groupby(['id', 'Date']).first().reset_index()\n",
    "\n",
    "# make dict of observation ID with original date\n",
    "observation_dates = {}\n",
    "for _, row in observations_df.iterrows():\n",
    "    observation_dates[row['id']] = row['Date']\n",
    "\n",
    "# Calculate difference between observation date and weather date\n",
    "def get_relative_day(row):\n",
    "    obs_date = observation_dates.get(row['id'])\n",
    "    this_date = pd.to_datetime(row['Date'])\n",
    "    difference = (this_date - obs_date).days\n",
    "    return difference\n",
    "\n",
    "# Apply the function to get relative day\n",
    "day_indices['RelativeDay'] = day_indices.apply(get_relative_day, axis=1)\n",
    "\n",
    "# Add relative day to weather_df\n",
    "day_map = day_indices.set_index(['id', 'Date'])['RelativeDay']\n",
    "weather_df['RelativeDay'] = weather_df.set_index(['id', 'Date']).index.map(day_map)\n",
    "\n",
    "# Variables to calculate aggregations for\n",
    "weather_vars = ['Temperature', 'Humidity', 'Wind Speed', 'Dew/Frost Point', \n",
    "                'Wet Bulb Temperature', 'Specific Humidity']\n",
    "\n",
    "# Time windows to aggregate over (days before and after the observation day)\n",
    "time_windows = {\n",
    "    'day_of': (0, 0),\n",
    "    'day_before_after': (-1, 1),\n",
    "    'three_days': (-3, 3),\n",
    "    'one_week': (-7, 7),\n",
    "    'two_weeks': (-14, 14)\n",
    "}\n",
    "\n",
    "# Function to calculate aggregates given ID and time window\n",
    "def calculate_aggregates(weather_subset, var_name, window_name, start_day, end_day):\n",
    "    # Filter data for given time window\n",
    "    window_data = weather_subset[(weather_subset['RelativeDay'] >= start_day) & (weather_subset['RelativeDay'] <= end_day)]\n",
    "    \n",
    "    # Calculate aggregate and return as a series\n",
    "    result = pd.Series({\n",
    "        f\"{var_name}_{window_name}_mean\": window_data[var_name].mean(),\n",
    "        f\"{var_name}_{window_name}_min\": window_data[var_name].min(),\n",
    "        f\"{var_name}_{window_name}_max\": window_data[var_name].max(),\n",
    "        f\"{var_name}_{window_name}_median\": window_data[var_name].median()\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Create empty DataFrame to store results\n",
    "all_features = []\n",
    "result_rows = []\n",
    "\n",
    "# For each observation row, calculate all aggregate weather data\n",
    "for id_val in observations_df['id'].unique():\n",
    "    id_weather = weather_df[weather_df['id'] == id_val]\n",
    "        \n",
    "    # Dictionary to store aggregated values for this ID\n",
    "    id_features = {'id': id_val}\n",
    "    \n",
    "    # Iterate over all weather data variables\n",
    "    for var in weather_vars:\n",
    "        # iterate over all items in time_windows\n",
    "        for window_name, (start_day, end_day) in time_windows.items():\n",
    "            aggs = calculate_aggregates(id_weather, var, window_name, start_day, end_day)\n",
    "            id_features.update(aggs)\n",
    "            \n",
    "            # Add feature names to our list (only once)\n",
    "            if id_val == observations_df['id'].unique()[0]:\n",
    "                all_features.extend(aggs.index.tolist())\n",
    "    \n",
    "    result_rows.append(id_features)\n",
    "\n",
    "# Create DataFrame from results\n",
    "aggregated_features = pd.DataFrame(result_rows)\n",
    "\n",
    "# Merge with the original observations dataframe\n",
    "observations_df = observations_df.merge(aggregated_features, on='id', how='left')\n",
    "\n",
    "# Create list of feature names\n",
    "weather_feature_names = all_features\n",
    "\n",
    "print(f\"Created {len(weather_feature_names)}  features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to decrease relationships between variables (such as the connections and potential spurrious correlations between powdery mildew and date_string, month, and day) we can combine this date information into one number: the day of the calendar year 1-365."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate day of year from year, month, and day\n",
    "from datetime import datetime\n",
    "\n",
    "# Add day of year as a feature to observations_df\n",
    "observations_df['day_of_year'] = observations_df.apply(\n",
    "    lambda row: datetime(row['year'], row['month'], row['day']).timetuple().tm_yday, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop rows with NaN values\n",
    "observations_df = observations_df.dropna()\n",
    "\n",
    "# Display the updated DataFrame\n",
    "observations_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to build a regression tree using this updated data frame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "features = weather_feature_names + ['day_of_year']\n",
    "target = 'PowderyMildew'\n",
    "\n",
    "X = observations_df[features]\n",
    "y = observations_df[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "#Save the model to be used in the api\n",
    "joblib.dump(rf_model, 'model.randomforest')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['False', 'True'], yticklabels=['False', 'True'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity has improved to 72%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Select top 20 features\n",
    "top_20_features = feature_importance_df.head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=top_20_features)\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature and seasonality are very important."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
